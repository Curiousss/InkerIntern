{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_DNST_CIFAR10_AUGC1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Curiousss/InkerIntern/blob/master/Copy_of_DNST_CIFAR10_AUGC1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 10\n",
        "num_filter = 20\n",
        "compression = 1\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qNTU3O3cuF6Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator #, array_to_img, img_to_array, load_img\n",
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "'''        vertical_flip=True,\n",
        "        rotation_range=40,\n",
        "        horizontal_flip=True\n",
        "     fill_mode='nearest',\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "'''\n",
        "train_gen = datagen.flow(x_train, y_train, batch_size)\n",
        "test_gen = datagen.flow(x_test, y_test, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#num_filter = 12\n",
        "#dropout_rate = 0.2\n",
        "#l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8364
        },
        "outputId": "0c4b01f6-d0ce-4590-cd1a-a556efb9f81e"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 32, 32, 20)   540         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 32, 32, 20)   80          conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 32, 32, 20)   0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 32, 32, 20)   3600        activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_247 (Dropout)           (None, 32, 32, 20)   0           conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_241 (Concatenate)   (None, 32, 32, 40)   0           conv2d_249[0][0]                 \n",
            "                                                                 dropout_247[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 32, 32, 40)   160         concatenate_241[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 32, 32, 40)   0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 32, 32, 20)   7200        activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_248 (Dropout)           (None, 32, 32, 20)   0           conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_242 (Concatenate)   (None, 32, 32, 60)   0           concatenate_241[0][0]            \n",
            "                                                                 dropout_248[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 32, 32, 60)   240         concatenate_242[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 32, 32, 60)   0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 32, 32, 20)   10800       activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_249 (Dropout)           (None, 32, 32, 20)   0           conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_243 (Concatenate)   (None, 32, 32, 80)   0           concatenate_242[0][0]            \n",
            "                                                                 dropout_249[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 32, 32, 80)   320         concatenate_243[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 32, 32, 80)   0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 32, 32, 20)   14400       activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_250 (Dropout)           (None, 32, 32, 20)   0           conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_244 (Concatenate)   (None, 32, 32, 100)  0           concatenate_243[0][0]            \n",
            "                                                                 dropout_250[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 32, 32, 100)  400         concatenate_244[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 32, 32, 100)  0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 32, 32, 20)   18000       activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_251 (Dropout)           (None, 32, 32, 20)   0           conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_245 (Concatenate)   (None, 32, 32, 120)  0           concatenate_244[0][0]            \n",
            "                                                                 dropout_251[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 32, 32, 120)  480         concatenate_245[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 32, 32, 120)  0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 32, 32, 20)   21600       activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_252 (Dropout)           (None, 32, 32, 20)   0           conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_246 (Concatenate)   (None, 32, 32, 140)  0           concatenate_245[0][0]            \n",
            "                                                                 dropout_252[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 32, 32, 140)  560         concatenate_246[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 32, 32, 140)  0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 32, 32, 20)   25200       activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_253 (Dropout)           (None, 32, 32, 20)   0           conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_247 (Concatenate)   (None, 32, 32, 160)  0           concatenate_246[0][0]            \n",
            "                                                                 dropout_253[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 32, 32, 160)  640         concatenate_247[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 32, 32, 160)  0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 32, 32, 20)   28800       activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_254 (Dropout)           (None, 32, 32, 20)   0           conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_248 (Concatenate)   (None, 32, 32, 180)  0           concatenate_247[0][0]            \n",
            "                                                                 dropout_254[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 32, 32, 180)  720         concatenate_248[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 32, 32, 180)  0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 32, 32, 20)   32400       activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_255 (Dropout)           (None, 32, 32, 20)   0           conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_249 (Concatenate)   (None, 32, 32, 200)  0           concatenate_248[0][0]            \n",
            "                                                                 dropout_255[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 32, 32, 200)  800         concatenate_249[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 32, 32, 200)  0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 32, 32, 20)   36000       activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_256 (Dropout)           (None, 32, 32, 20)   0           conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_250 (Concatenate)   (None, 32, 32, 220)  0           concatenate_249[0][0]            \n",
            "                                                                 dropout_256[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 32, 32, 220)  880         concatenate_250[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 32, 32, 220)  0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 32, 32, 20)   4400        activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_257 (Dropout)           (None, 32, 32, 20)   0           conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 20)   0           dropout_257[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 16, 16, 20)   80          average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 16, 16, 20)   0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 16, 16, 20)   3600        activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_258 (Dropout)           (None, 16, 16, 20)   0           conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_251 (Concatenate)   (None, 16, 16, 40)   0           average_pooling2d_9[0][0]        \n",
            "                                                                 dropout_258[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 16, 16, 40)   160         concatenate_251[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 16, 16, 40)   0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 16, 16, 20)   7200        activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_259 (Dropout)           (None, 16, 16, 20)   0           conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_252 (Concatenate)   (None, 16, 16, 60)   0           concatenate_251[0][0]            \n",
            "                                                                 dropout_259[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 16, 16, 60)   240         concatenate_252[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 16, 16, 60)   0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 16, 16, 20)   10800       activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_260 (Dropout)           (None, 16, 16, 20)   0           conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_253 (Concatenate)   (None, 16, 16, 80)   0           concatenate_252[0][0]            \n",
            "                                                                 dropout_260[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 16, 16, 80)   320         concatenate_253[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 16, 16, 80)   0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 16, 16, 20)   14400       activation_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_261 (Dropout)           (None, 16, 16, 20)   0           conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_254 (Concatenate)   (None, 16, 16, 100)  0           concatenate_253[0][0]            \n",
            "                                                                 dropout_261[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 16, 16, 100)  400         concatenate_254[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 16, 16, 100)  0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 16, 16, 20)   18000       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_262 (Dropout)           (None, 16, 16, 20)   0           conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_255 (Concatenate)   (None, 16, 16, 120)  0           concatenate_254[0][0]            \n",
            "                                                                 dropout_262[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 16, 16, 120)  480         concatenate_255[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 16, 16, 120)  0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 16, 16, 20)   21600       activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_263 (Dropout)           (None, 16, 16, 20)   0           conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_256 (Concatenate)   (None, 16, 16, 140)  0           concatenate_255[0][0]            \n",
            "                                                                 dropout_263[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 16, 16, 140)  560         concatenate_256[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 16, 16, 140)  0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 16, 16, 20)   25200       activation_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_264 (Dropout)           (None, 16, 16, 20)   0           conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_257 (Concatenate)   (None, 16, 16, 160)  0           concatenate_256[0][0]            \n",
            "                                                                 dropout_264[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 16, 16, 160)  640         concatenate_257[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 16, 16, 160)  0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 16, 16, 20)   28800       activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_265 (Dropout)           (None, 16, 16, 20)   0           conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_258 (Concatenate)   (None, 16, 16, 180)  0           concatenate_257[0][0]            \n",
            "                                                                 dropout_265[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 16, 16, 180)  720         concatenate_258[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 16, 16, 180)  0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 16, 16, 20)   32400       activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_266 (Dropout)           (None, 16, 16, 20)   0           conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_259 (Concatenate)   (None, 16, 16, 200)  0           concatenate_258[0][0]            \n",
            "                                                                 dropout_266[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 16, 16, 200)  800         concatenate_259[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 16, 16, 200)  0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 16, 16, 20)   36000       activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_267 (Dropout)           (None, 16, 16, 20)   0           conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_260 (Concatenate)   (None, 16, 16, 220)  0           concatenate_259[0][0]            \n",
            "                                                                 dropout_267[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 16, 16, 220)  880         concatenate_260[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 16, 16, 220)  0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 16, 16, 20)   4400        activation_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_268 (Dropout)           (None, 16, 16, 20)   0           conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 8, 8, 20)     0           dropout_268[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 8, 8, 20)     80          average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 8, 8, 20)     0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 8, 8, 20)     3600        activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_269 (Dropout)           (None, 8, 8, 20)     0           conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_261 (Concatenate)   (None, 8, 8, 40)     0           average_pooling2d_10[0][0]       \n",
            "                                                                 dropout_269[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 8, 8, 40)     160         concatenate_261[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 8, 8, 40)     0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 8, 8, 20)     7200        activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_270 (Dropout)           (None, 8, 8, 20)     0           conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_262 (Concatenate)   (None, 8, 8, 60)     0           concatenate_261[0][0]            \n",
            "                                                                 dropout_270[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 8, 8, 60)     240         concatenate_262[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 8, 8, 60)     0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 8, 8, 20)     10800       activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_271 (Dropout)           (None, 8, 8, 20)     0           conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_263 (Concatenate)   (None, 8, 8, 80)     0           concatenate_262[0][0]            \n",
            "                                                                 dropout_271[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 8, 8, 80)     320         concatenate_263[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 8, 8, 80)     0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 8, 8, 20)     14400       activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_272 (Dropout)           (None, 8, 8, 20)     0           conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_264 (Concatenate)   (None, 8, 8, 100)    0           concatenate_263[0][0]            \n",
            "                                                                 dropout_272[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 8, 8, 100)    400         concatenate_264[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 8, 8, 100)    0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 8, 8, 20)     18000       activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_273 (Dropout)           (None, 8, 8, 20)     0           conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_265 (Concatenate)   (None, 8, 8, 120)    0           concatenate_264[0][0]            \n",
            "                                                                 dropout_273[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 8, 8, 120)    480         concatenate_265[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 8, 8, 120)    0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 8, 8, 20)     21600       activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_274 (Dropout)           (None, 8, 8, 20)     0           conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_266 (Concatenate)   (None, 8, 8, 140)    0           concatenate_265[0][0]            \n",
            "                                                                 dropout_274[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 8, 8, 140)    560         concatenate_266[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 8, 8, 140)    0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 8, 8, 20)     25200       activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_275 (Dropout)           (None, 8, 8, 20)     0           conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_267 (Concatenate)   (None, 8, 8, 160)    0           concatenate_266[0][0]            \n",
            "                                                                 dropout_275[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 8, 8, 160)    640         concatenate_267[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 8, 8, 160)    0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 8, 8, 20)     28800       activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_276 (Dropout)           (None, 8, 8, 20)     0           conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_268 (Concatenate)   (None, 8, 8, 180)    0           concatenate_267[0][0]            \n",
            "                                                                 dropout_276[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 8, 8, 180)    720         concatenate_268[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 8, 8, 180)    0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 8, 8, 20)     32400       activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_277 (Dropout)           (None, 8, 8, 20)     0           conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_269 (Concatenate)   (None, 8, 8, 200)    0           concatenate_268[0][0]            \n",
            "                                                                 dropout_277[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 8, 8, 200)    800         concatenate_269[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 8, 8, 200)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 8, 8, 20)     36000       activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_278 (Dropout)           (None, 8, 8, 20)     0           conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_270 (Concatenate)   (None, 8, 8, 220)    0           concatenate_269[0][0]            \n",
            "                                                                 dropout_278[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 8, 8, 220)    880         concatenate_270[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 8, 8, 220)    0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 8, 8, 20)     4400        activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_279 (Dropout)           (None, 8, 8, 20)     0           conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 4, 4, 20)     0           dropout_279[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 4, 4, 20)     80          average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 4, 4, 20)     0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 4, 4, 20)     3600        activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_280 (Dropout)           (None, 4, 4, 20)     0           conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_271 (Concatenate)   (None, 4, 4, 40)     0           average_pooling2d_11[0][0]       \n",
            "                                                                 dropout_280[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 4, 4, 40)     160         concatenate_271[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 4, 4, 40)     0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 4, 4, 20)     7200        activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_281 (Dropout)           (None, 4, 4, 20)     0           conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_272 (Concatenate)   (None, 4, 4, 60)     0           concatenate_271[0][0]            \n",
            "                                                                 dropout_281[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 4, 4, 60)     240         concatenate_272[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 4, 4, 60)     0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 4, 4, 20)     10800       activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_282 (Dropout)           (None, 4, 4, 20)     0           conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_273 (Concatenate)   (None, 4, 4, 80)     0           concatenate_272[0][0]            \n",
            "                                                                 dropout_282[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 4, 4, 80)     320         concatenate_273[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 4, 4, 80)     0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 4, 4, 20)     14400       activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_283 (Dropout)           (None, 4, 4, 20)     0           conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_274 (Concatenate)   (None, 4, 4, 100)    0           concatenate_273[0][0]            \n",
            "                                                                 dropout_283[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 4, 4, 100)    400         concatenate_274[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 4, 4, 100)    0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 4, 4, 20)     18000       activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_284 (Dropout)           (None, 4, 4, 20)     0           conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_275 (Concatenate)   (None, 4, 4, 120)    0           concatenate_274[0][0]            \n",
            "                                                                 dropout_284[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 4, 4, 120)    480         concatenate_275[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 4, 4, 120)    0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 4, 4, 20)     21600       activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_285 (Dropout)           (None, 4, 4, 20)     0           conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_276 (Concatenate)   (None, 4, 4, 140)    0           concatenate_275[0][0]            \n",
            "                                                                 dropout_285[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 4, 4, 140)    560         concatenate_276[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 4, 4, 140)    0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 4, 4, 20)     25200       activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_286 (Dropout)           (None, 4, 4, 20)     0           conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_277 (Concatenate)   (None, 4, 4, 160)    0           concatenate_276[0][0]            \n",
            "                                                                 dropout_286[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 4, 4, 160)    640         concatenate_277[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 4, 4, 160)    0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 4, 4, 20)     28800       activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_287 (Dropout)           (None, 4, 4, 20)     0           conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_278 (Concatenate)   (None, 4, 4, 180)    0           concatenate_277[0][0]            \n",
            "                                                                 dropout_287[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 4, 4, 180)    720         concatenate_278[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 4, 4, 180)    0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 4, 4, 20)     32400       activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_288 (Dropout)           (None, 4, 4, 20)     0           conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_279 (Concatenate)   (None, 4, 4, 200)    0           concatenate_278[0][0]            \n",
            "                                                                 dropout_288[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 4, 4, 200)    800         concatenate_279[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 4, 4, 200)    0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 4, 4, 20)     36000       activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_289 (Dropout)           (None, 4, 4, 20)     0           conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_280 (Concatenate)   (None, 4, 4, 220)    0           concatenate_279[0][0]            \n",
            "                                                                 dropout_289[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 4, 4, 220)    880         concatenate_280[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 4, 4, 220)    0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 2, 2, 220)    0           activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 880)          0           average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           8810        flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 835,670\n",
            "Trainable params: 825,110\n",
            "Non-trainable params: 10,560\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1754
        },
        "outputId": "92c0a9b4-c08c-4e31-dc1f-2cb302e5e1c5"
      },
      "cell_type": "code",
      "source": [
        "'''model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "'''\n",
        "model.fit_generator(train_gen,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "#                    steps_per_epoch=len(x_train),\n",
        "                    validation_data=test_gen)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 293s 750ms/step - loss: 1.5254 - acc: 0.4378 - val_loss: 1.3454 - val_acc: 0.5239\n",
            "Epoch 2/50\n",
            "280/391 [====================>.........] - ETA: 1:12 - loss: 1.1603 - acc: 0.5847"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 690ms/step - loss: 1.1243 - acc: 0.5992 - val_loss: 1.7389 - val_acc: 0.4965\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 270s 690ms/step - loss: 0.9329 - acc: 0.6692 - val_loss: 0.9993 - val_acc: 0.6592\n",
            "Epoch 4/50\n",
            " 16/391 [>.............................] - ETA: 4:01 - loss: 0.8555 - acc: 0.6978"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 690ms/step - loss: 0.8253 - acc: 0.7102 - val_loss: 1.6687 - val_acc: 0.5602\n",
            "Epoch 5/50\n",
            "320/391 [=======================>......] - ETA: 46s - loss: 0.7602 - acc: 0.7325"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 690ms/step - loss: 0.7554 - acc: 0.7341 - val_loss: 1.3851 - val_acc: 0.6036\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 270s 690ms/step - loss: 0.7024 - acc: 0.7516 - val_loss: 0.7969 - val_acc: 0.7442\n",
            "Epoch 7/50\n",
            " 25/391 [>.............................] - ETA: 3:57 - loss: 0.6318 - acc: 0.7816"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 690ms/step - loss: 0.6548 - acc: 0.7705 - val_loss: 1.1368 - val_acc: 0.6677\n",
            "Epoch 8/50\n",
            "323/391 [=======================>......] - ETA: 44s - loss: 0.6186 - acc: 0.7811"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 690ms/step - loss: 0.6191 - acc: 0.7818 - val_loss: 1.0968 - val_acc: 0.6800\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 270s 690ms/step - loss: 0.5903 - acc: 0.7944 - val_loss: 1.2524 - val_acc: 0.6465\n",
            "Epoch 10/50\n",
            " 26/391 [>.............................] - ETA: 3:57 - loss: 0.6032 - acc: 0.7921"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 690ms/step - loss: 0.5688 - acc: 0.8030 - val_loss: 0.9842 - val_acc: 0.7179\n",
            "Epoch 11/50\n",
            "322/391 [=======================>......] - ETA: 44s - loss: 0.5422 - acc: 0.8114"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 693ms/step - loss: 0.5414 - acc: 0.8112 - val_loss: 0.9406 - val_acc: 0.7313\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 269s 688ms/step - loss: 0.5202 - acc: 0.8167 - val_loss: 0.7818 - val_acc: 0.7688\n",
            "Epoch 13/50\n",
            " 24/391 [>.............................] - ETA: 3:57 - loss: 0.4900 - acc: 0.8275"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 269s 687ms/step - loss: 0.5106 - acc: 0.8234 - val_loss: 0.7455 - val_acc: 0.7717\n",
            "Epoch 14/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.4911 - acc: 0.8304"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 269s 688ms/step - loss: 0.4882 - acc: 0.8314 - val_loss: 0.8391 - val_acc: 0.7454\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 268s 687ms/step - loss: 0.4724 - acc: 0.8356 - val_loss: 0.8022 - val_acc: 0.7697\n",
            "Epoch 16/50\n",
            " 24/391 [>.............................] - ETA: 3:55 - loss: 0.4324 - acc: 0.8493"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 269s 687ms/step - loss: 0.4573 - acc: 0.8404 - val_loss: 0.9389 - val_acc: 0.7424\n",
            "Epoch 17/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.4496 - acc: 0.8433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 269s 688ms/step - loss: 0.4487 - acc: 0.8436 - val_loss: 0.7016 - val_acc: 0.7824\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 270s 690ms/step - loss: 0.4374 - acc: 0.8468 - val_loss: 0.8373 - val_acc: 0.7634\n",
            "Epoch 19/50\n",
            " 24/391 [>.............................] - ETA: 3:57 - loss: 0.3926 - acc: 0.8649"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 690ms/step - loss: 0.4219 - acc: 0.8532 - val_loss: 0.8779 - val_acc: 0.7486\n",
            "Epoch 20/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.4096 - acc: 0.8572"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 691ms/step - loss: 0.4124 - acc: 0.8555 - val_loss: 0.5412 - val_acc: 0.8360\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 270s 691ms/step - loss: 0.4076 - acc: 0.8579 - val_loss: 0.7695 - val_acc: 0.7859\n",
            "Epoch 22/50\n",
            " 24/391 [>.............................] - ETA: 3:58 - loss: 0.3918 - acc: 0.8617"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 690ms/step - loss: 0.3915 - acc: 0.8636 - val_loss: 0.7730 - val_acc: 0.7784\n",
            "Epoch 23/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.3855 - acc: 0.8648"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 693ms/step - loss: 0.3843 - acc: 0.8652 - val_loss: 0.6279 - val_acc: 0.8093\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 271s 694ms/step - loss: 0.3767 - acc: 0.8668 - val_loss: 0.5564 - val_acc: 0.8265\n",
            "Epoch 25/50\n",
            " 24/391 [>.............................] - ETA: 3:59 - loss: 0.3869 - acc: 0.8649"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 694ms/step - loss: 0.3714 - acc: 0.8703 - val_loss: 0.7539 - val_acc: 0.7866\n",
            "Epoch 26/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.3577 - acc: 0.8753"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 693ms/step - loss: 0.3580 - acc: 0.8759 - val_loss: 0.7890 - val_acc: 0.7872\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 270s 690ms/step - loss: 0.3550 - acc: 0.8758 - val_loss: 0.7166 - val_acc: 0.8051\n",
            "Epoch 28/50\n",
            " 24/391 [>.............................] - ETA: 3:57 - loss: 0.3453 - acc: 0.8714"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 269s 689ms/step - loss: 0.3489 - acc: 0.8753 - val_loss: 0.6376 - val_acc: 0.8171\n",
            "Epoch 29/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.3392 - acc: 0.8816"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 693ms/step - loss: 0.3395 - acc: 0.8811 - val_loss: 0.5203 - val_acc: 0.8416\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 271s 693ms/step - loss: 0.3316 - acc: 0.8838 - val_loss: 0.4474 - val_acc: 0.8581\n",
            "Epoch 31/50\n",
            " 24/391 [>.............................] - ETA: 3:58 - loss: 0.3151 - acc: 0.8968"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 269s 689ms/step - loss: 0.3255 - acc: 0.8870 - val_loss: 0.5053 - val_acc: 0.8489\n",
            "Epoch 32/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.3190 - acc: 0.8890"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 692ms/step - loss: 0.3195 - acc: 0.8885 - val_loss: 0.5871 - val_acc: 0.8295\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 270s 692ms/step - loss: 0.3185 - acc: 0.8886 - val_loss: 0.5679 - val_acc: 0.8348\n",
            "Epoch 34/50\n",
            " 24/391 [>.............................] - ETA: 3:58 - loss: 0.3255 - acc: 0.8883"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 692ms/step - loss: 0.3171 - acc: 0.8899 - val_loss: 1.0263 - val_acc: 0.7424\n",
            "Epoch 35/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.3029 - acc: 0.8927"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 691ms/step - loss: 0.3049 - acc: 0.8921 - val_loss: 0.4875 - val_acc: 0.8558\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 271s 693ms/step - loss: 0.3020 - acc: 0.8940 - val_loss: 0.6321 - val_acc: 0.8199\n",
            "Epoch 37/50\n",
            " 24/391 [>.............................] - ETA: 3:59 - loss: 0.2516 - acc: 0.9128"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 692ms/step - loss: 0.2962 - acc: 0.8968 - val_loss: 0.5188 - val_acc: 0.8451\n",
            "Epoch 38/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.2887 - acc: 0.9007"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 691ms/step - loss: 0.2926 - acc: 0.8988 - val_loss: 0.6089 - val_acc: 0.8365\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 269s 689ms/step - loss: 0.2845 - acc: 0.9004 - val_loss: 0.5707 - val_acc: 0.8357\n",
            "Epoch 40/50\n",
            " 24/391 [>.............................] - ETA: 3:59 - loss: 0.2726 - acc: 0.8975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 693ms/step - loss: 0.2861 - acc: 0.8998 - val_loss: 0.4428 - val_acc: 0.8645\n",
            "Epoch 41/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.2795 - acc: 0.9003"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 693ms/step - loss: 0.2792 - acc: 0.9013 - val_loss: 0.7248 - val_acc: 0.8077\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 271s 693ms/step - loss: 0.2711 - acc: 0.9048 - val_loss: 0.6205 - val_acc: 0.8344\n",
            "Epoch 43/50\n",
            " 24/391 [>.............................] - ETA: 3:59 - loss: 0.2736 - acc: 0.9023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 693ms/step - loss: 0.2730 - acc: 0.9025 - val_loss: 0.4209 - val_acc: 0.8721\n",
            "Epoch 44/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.2684 - acc: 0.9046"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 692ms/step - loss: 0.2688 - acc: 0.9050 - val_loss: 0.4918 - val_acc: 0.8558\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 270s 691ms/step - loss: 0.2668 - acc: 0.9060 - val_loss: 0.5170 - val_acc: 0.8529\n",
            "Epoch 46/50\n",
            " 24/391 [>.............................] - ETA: 3:59 - loss: 0.2547 - acc: 0.9023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 271s 693ms/step - loss: 0.2584 - acc: 0.9087 - val_loss: 0.4756 - val_acc: 0.8667\n",
            "Epoch 47/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.2591 - acc: 0.9083"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 269s 688ms/step - loss: 0.2594 - acc: 0.9082 - val_loss: 0.4485 - val_acc: 0.8697\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 268s 686ms/step - loss: 0.2508 - acc: 0.9109 - val_loss: 0.6551 - val_acc: 0.8253\n",
            "Epoch 49/50\n",
            " 24/391 [>.............................] - ETA: 4:00 - loss: 0.2674 - acc: 0.8981"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 270s 691ms/step - loss: 0.2491 - acc: 0.9116 - val_loss: 0.6546 - val_acc: 0.8259\n",
            "Epoch 50/50\n",
            "321/391 [=======================>......] - ETA: 45s - loss: 0.2480 - acc: 0.9134"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 269s 688ms/step - loss: 0.2486 - acc: 0.9126 - val_loss: 0.5593 - val_acc: 0.8522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb619173048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eac047ab-aa85-410e-ec17-87aef4b01cef"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 23s 2ms/step\n",
            "Test loss: 0.6152515197515488\n",
            "Test accuracy: 0.8407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e032cb11-fb86-497c-c0ba-a2c7c99c1e64"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}