{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER_WINO_SEPARABLE_NO_CUDNN (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Curiousss/InkerIntern/blob/master/FER_WINO_SEPARABLE_NO_CUDNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Q9eNowMGaO_J",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "a3a87222-84b1-46ee-cd53-a612a6c16f61"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2e8d2f4b-a1cd-41f1-bf1b-1324f7b2d5c3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2e8d2f4b-a1cd-41f1-bf1b-1324f7b2d5c3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving fer2013.tar to fer2013 (1).tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     result = output.eval_js(\n\u001b[1;32m     69\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[0;32m---> 70\u001b[0;31m             output_id=output_id))\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'append'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;31m# JS side uses a generator of promises to process all of the files- some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BEb9SWJUV8T2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f3eccb7-ac4a-4d83-b850-32527e4b1eef"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "baddata.txt  datalab  fer2013  fer2013 (1).tar\tfer2013.tar\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ldEdUzQbuQIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "fa1f7c30-c8b0-4725-b742-3500ee1754bb"
      },
      "cell_type": "code",
      "source": [
        "!tar xvf fer2013.tar\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fer2013/fer2013.csv\n",
            "fer2013/README\n",
            "fer2013/fer2013.bib\n",
            "fer2013/\n",
            "datalab  fer2013  fer2013.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dTyUIGDeuAQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3d4cb354-340e-4675-85b1-51748bfa2c93"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D, InputLayer\n",
        "from keras.layers import Convolution2D, SeparableConv2D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OqJCQeGxhq4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 48, 48\n",
        "batch_size = 64\n",
        "classes = 7\n",
        "epoch = 100\n",
        "img_channels = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sq7nNsVmhsYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "f = open('fer2013/fer2013.csv')\n",
        "csv_f = csv.reader(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQSDhHZ3tKqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "val_x =[]\n",
        "val_y =[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eWmuGFqNF5Ds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ToBeRemovedTrainingData = []\n",
        "with open(\"baddata.txt\", \"r\") as text:\n",
        "  for line in text:\n",
        "    ToBeRemovedTrainingData.append(int(line))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HmmgpkTpiWyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num=0\n",
        "for row in csv_f:\n",
        "  num = num +1\n",
        "  if num in ToBeRemovedTrainingData or num==1:\n",
        "    continue\n",
        "  #print(row)\n",
        "  #print(num)\n",
        "  temp_list = []\n",
        "  for pixel in row[1].split( ):\n",
        "    temp_list.append(int(pixel))\n",
        "\n",
        "  if str(row[2]) == \"Training\":\n",
        "    train_y.append(int(row[0]))\n",
        "    train_x.append(temp_list) \n",
        "  elif str(row[2]) == \"PublicTest\":\n",
        "    val_y.append(int(row[0]))\n",
        "    val_x.append(temp_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6rDJXl4rUKS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = np.asarray(train_x)\n",
        "train_y = np.asarray(train_y)\n",
        "val_x = np.asarray(val_x)\n",
        "val_y = np.asarray(val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lmXwV3InrVsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = train_x.reshape(train_x.shape[0], 48, 48)\n",
        "train_x = train_x.reshape(train_x.shape[0], 48, 48, 1 )\n",
        "train_y = np_utils.to_categorical(train_y, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3iZUfL1ztRu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_x = val_x.reshape(val_x.shape[0], 48, 48)\n",
        "val_x = val_x.reshape(val_x.shape[0], 48, 48, 1)\n",
        "val_y = np_utils.to_categorical(val_y, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FAWueVKKI0CR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "adef5ce2-57d8-4c8c-bcba-0eb0de1267dc"
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "#print(train_x.shape)\n",
        "\n",
        "showimg = train_x[1].reshape(48,48)\n",
        "img = Image.fromarray(showimg.astype('uint8'))\n",
        "from IPython.display import display\n",
        "display(img)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAHO0lEQVR4nAXB2Y4cVxkA4LP8Z6ut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\nFH15IbD7P4euDm5pw/eMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48 at 0x7FBC2865C4A8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bkb-p1BXzBrI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = train_x.astype('float32')\n",
        "train_x = train_x / 255.0\n",
        "val_x = val_x.astype('float32')\n",
        "val_x = val_x / 255.0\n",
        "train_x = train_x - 0.5\n",
        "train_x = train_x * 2\n",
        "val_x = val_x - 0.5\n",
        "val_x = val_x * 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMKS1KOEGsB3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = (img_rows, img_cols, img_channels)\n",
        "model = Sequential()\n",
        "model.add(SeparableConv2D(filters=64, kernel_size=(3, 3), padding='same',\n",
        "                            name='image_array', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=512, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=512, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(.3))\n",
        "'''\n",
        "model.add(SeparableConv2D(filters=1024, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=1024, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "'''\n",
        "#model.add(Flatten())\n",
        "'''\n",
        "model.add(Dense(1024))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(2048))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "'''\n",
        "model.add(InputLayer(input_shape=(3, 3, 1024)))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "\n",
        "model.add(Dense(2048))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(7))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRsZspcA0uxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1454
        },
        "outputId": "6791d992-92ec-4353-d472-853ff3592c09"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "image_array (SeparableConv2D (None, 48, 48, 64)        153       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_1 (Separabl (None, 48, 48, 64)        5760      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_2 (Separabl (None, 24, 24, 128)       9920      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_3 (Separabl (None, 24, 24, 128)       19712     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_4 (Separabl (None, 12, 12, 256)       36224     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_5 (Separabl (None, 12, 12, 256)       72192     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_6 (Separabl (None, 6, 6, 512)         137984    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_7 (Separabl (None, 6, 6, 512)         275456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "input_1 (InputLayer)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 3591      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 568,672\n",
            "Trainable params: 564,832\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hy0FyCcc2li0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "filepath='Model.best.hdf5'\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZYe0RPXn4O_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('Model.best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJiUe6bEgjHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3692
        },
        "outputId": "34d26d13-27ee-4aa7-9ac8-7100027bea02"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2)  # randomly flip images\n",
        "\n",
        "datagen.fit(train_x)\n",
        "\n",
        "model.fit_generator(datagen.flow(train_x, train_y,\n",
        "                    batch_size=batch_size),\n",
        "                    steps_per_epoch=(train_x.shape[0]/batch_size),\n",
        "                    epochs=50,\n",
        "                    validation_data=(val_x, val_y),\n",
        "                    callbacks=[checkpointer])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6746 - acc: 0.7477 - val_loss: 1.0577 - val_acc: 0.6494\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.66611\n",
            "Epoch 2/50\n",
            "214/446 [=============>................] - ETA: 29s - loss: 0.6682 - acc: 0.7515"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6784 - acc: 0.7477 - val_loss: 1.0866 - val_acc: 0.6527\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.66611\n",
            "Epoch 3/50\n",
            "305/446 [===================>..........] - ETA: 18s - loss: 0.6634 - acc: 0.7535"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6696 - acc: 0.7515 - val_loss: 1.0612 - val_acc: 0.6469\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.66611\n",
            "Epoch 4/50\n",
            "333/446 [=====================>........] - ETA: 14s - loss: 0.6727 - acc: 0.7491"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6718 - acc: 0.7493 - val_loss: 1.0725 - val_acc: 0.6692\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.66611 to 0.66918, saving model to Model.best.hdf5\n",
            "Epoch 5/50\n",
            "299/446 [===================>..........] - ETA: 19s - loss: 0.6650 - acc: 0.7535"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6701 - acc: 0.7534 - val_loss: 1.0807 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.66918\n",
            "Epoch 6/50\n",
            "331/446 [=====================>........] - ETA: 14s - loss: 0.6587 - acc: 0.7558"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 133ms/step - loss: 0.6606 - acc: 0.7538 - val_loss: 1.1146 - val_acc: 0.6505\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.66918\n",
            "Epoch 7/50\n",
            "340/446 [=====================>........] - ETA: 13s - loss: 0.6606 - acc: 0.7552"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6635 - acc: 0.7550 - val_loss: 1.0724 - val_acc: 0.6661\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.66918\n",
            "Epoch 8/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.6611 - acc: 0.7551"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6661 - acc: 0.7529 - val_loss: 1.0590 - val_acc: 0.6697\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.66918 to 0.66974, saving model to Model.best.hdf5\n",
            "Epoch 9/50\n",
            "301/446 [===================>..........] - ETA: 18s - loss: 0.6583 - acc: 0.7553"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6597 - acc: 0.7561 - val_loss: 1.1215 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.66974\n",
            "Epoch 10/50\n",
            "330/446 [=====================>........] - ETA: 15s - loss: 0.6470 - acc: 0.7584"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6505 - acc: 0.7572 - val_loss: 1.0738 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.66974\n",
            "Epoch 11/50\n",
            "339/446 [=====================>........] - ETA: 13s - loss: 0.6425 - acc: 0.7609"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6509 - acc: 0.7587 - val_loss: 1.1332 - val_acc: 0.6555\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.66974\n",
            "Epoch 12/50\n",
            "341/446 [=====================>........] - ETA: 13s - loss: 0.6412 - acc: 0.7630"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 133ms/step - loss: 0.6447 - acc: 0.7626 - val_loss: 1.0826 - val_acc: 0.6572\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.66974\n",
            "Epoch 13/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6448 - acc: 0.7642"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6474 - acc: 0.7609 - val_loss: 1.1077 - val_acc: 0.6630\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.66974\n",
            "Epoch 14/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6396 - acc: 0.7598"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6444 - acc: 0.7586 - val_loss: 1.1309 - val_acc: 0.6538\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.66974\n",
            "Epoch 15/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6439 - acc: 0.7605"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6504 - acc: 0.7587 - val_loss: 1.1011 - val_acc: 0.6603\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.66974\n",
            "Epoch 16/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6484 - acc: 0.7588"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6481 - acc: 0.7586 - val_loss: 1.0947 - val_acc: 0.6633\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.66974\n",
            "Epoch 17/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6398 - acc: 0.7636"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 133ms/step - loss: 0.6414 - acc: 0.7627 - val_loss: 1.1143 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.66974\n",
            "Epoch 18/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6345 - acc: 0.7625"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6374 - acc: 0.7616 - val_loss: 1.0642 - val_acc: 0.6661\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.66974\n",
            "Epoch 19/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6342 - acc: 0.7631"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6367 - acc: 0.7614 - val_loss: 1.1194 - val_acc: 0.6608\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.66974\n",
            "Epoch 20/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6316 - acc: 0.7659"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6394 - acc: 0.7617 - val_loss: 1.1354 - val_acc: 0.6499\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.66974\n",
            "Epoch 21/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6353 - acc: 0.7647"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6376 - acc: 0.7639 - val_loss: 1.0859 - val_acc: 0.6597\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.66974\n",
            "Epoch 22/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6305 - acc: 0.7664"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6353 - acc: 0.7639 - val_loss: 1.1046 - val_acc: 0.6544\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.66974\n",
            "Epoch 23/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6272 - acc: 0.7657"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6321 - acc: 0.7640 - val_loss: 1.0630 - val_acc: 0.6697\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.66974\n",
            "Epoch 24/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6222 - acc: 0.7700"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6249 - acc: 0.7696 - val_loss: 1.0964 - val_acc: 0.6572\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.66974\n",
            "Epoch 25/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6214 - acc: 0.7690"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6271 - acc: 0.7664 - val_loss: 1.1688 - val_acc: 0.6497\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.66974\n",
            "Epoch 26/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6229 - acc: 0.7678"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6257 - acc: 0.7670 - val_loss: 1.1117 - val_acc: 0.6544\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.66974\n",
            "Epoch 27/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6164 - acc: 0.7685"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6172 - acc: 0.7698 - val_loss: 1.1303 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.66974\n",
            "Epoch 28/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6151 - acc: 0.7746"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6192 - acc: 0.7723 - val_loss: 1.1462 - val_acc: 0.6605\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.66974\n",
            "Epoch 29/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6207 - acc: 0.7705"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6228 - acc: 0.7706 - val_loss: 1.1513 - val_acc: 0.6547\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.66974\n",
            "Epoch 30/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6218 - acc: 0.7682"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6210 - acc: 0.7685 - val_loss: 1.1426 - val_acc: 0.6577\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.66974\n",
            "Epoch 31/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6100 - acc: 0.7715"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6162 - acc: 0.7705 - val_loss: 1.1107 - val_acc: 0.6575\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.66974\n",
            "Epoch 32/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6059 - acc: 0.7735"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6133 - acc: 0.7707 - val_loss: 1.1065 - val_acc: 0.6616\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.66974\n",
            "Epoch 33/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6147 - acc: 0.7674"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6147 - acc: 0.7680 - val_loss: 1.0947 - val_acc: 0.6672\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.66974\n",
            "Epoch 34/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6070 - acc: 0.7745"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6068 - acc: 0.7751 - val_loss: 1.1334 - val_acc: 0.6550\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.66974\n",
            "Epoch 35/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5981 - acc: 0.7771"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6076 - acc: 0.7722 - val_loss: 1.2020 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.66974\n",
            "Epoch 36/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.6063 - acc: 0.7764"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6100 - acc: 0.7744 - val_loss: 1.1560 - val_acc: 0.6441\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.66974\n",
            "Epoch 37/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5998 - acc: 0.7752"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6038 - acc: 0.7749 - val_loss: 1.1957 - val_acc: 0.6488\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.66974\n",
            "Epoch 38/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5972 - acc: 0.7801"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6025 - acc: 0.7777 - val_loss: 1.1494 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.66974\n",
            "Epoch 39/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5901 - acc: 0.7816"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.6016 - acc: 0.7775 - val_loss: 1.1535 - val_acc: 0.6600\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.66974\n",
            "Epoch 40/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5972 - acc: 0.7811"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5990 - acc: 0.7809 - val_loss: 1.1548 - val_acc: 0.6583\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.66974\n",
            "Epoch 41/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5938 - acc: 0.7768"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5970 - acc: 0.7767 - val_loss: 1.1509 - val_acc: 0.6628\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.66974\n",
            "Epoch 42/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5836 - acc: 0.7847"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5899 - acc: 0.7817 - val_loss: 1.1828 - val_acc: 0.6555\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.66974\n",
            "Epoch 43/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5872 - acc: 0.7830"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5927 - acc: 0.7807 - val_loss: 1.1482 - val_acc: 0.6566\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.66974\n",
            "Epoch 44/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5867 - acc: 0.7821"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5896 - acc: 0.7803 - val_loss: 1.1830 - val_acc: 0.6558\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.66974\n",
            "Epoch 45/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5924 - acc: 0.7783"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5921 - acc: 0.7787 - val_loss: 1.2025 - val_acc: 0.6508\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.66974\n",
            "Epoch 46/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5799 - acc: 0.7849"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5871 - acc: 0.7822 - val_loss: 1.1510 - val_acc: 0.6572\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.66974\n",
            "Epoch 47/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5864 - acc: 0.7805"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5883 - acc: 0.7786 - val_loss: 1.2302 - val_acc: 0.6483\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.66974\n",
            "Epoch 48/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5778 - acc: 0.7840"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5782 - acc: 0.7841 - val_loss: 1.1814 - val_acc: 0.6499\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.66974\n",
            "Epoch 49/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5779 - acc: 0.7862"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5770 - acc: 0.7854 - val_loss: 1.1530 - val_acc: 0.6611\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.66974\n",
            "Epoch 50/50\n",
            "342/446 [=====================>........] - ETA: 13s - loss: 0.5750 - acc: 0.7876"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 60s 134ms/step - loss: 0.5769 - acc: 0.7864 - val_loss: 1.2001 - val_acc: 0.6505\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.66974\n",
            "--- 2991.623815536499 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WMaPXKT8FSGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "a0d5cdf5-008e-4b13-cf13-11adae5e0d85"
      },
      "cell_type": "code",
      "source": [
        "def predict_emotion(model, pic):\n",
        "  pic = pic.convert('L')\n",
        "  pic = pic.resize((48,48))\n",
        "  \n",
        "  from IPython.display import display\n",
        "  display(pic)\n",
        "  pic_np=np.asarray(pic)#.getdata()).reshape(48, 48, 1)\n",
        "  pic_np = pic_np.reshape(1, 48, 48, 1)\n",
        "  print(pic_np.shape)\n",
        "  pic_np = pic_np / 255.0\n",
        "  pic_np = pic_np - 0.5\n",
        "  pic_np = pic_np * 2\n",
        "  \n",
        "  print(pic_np.shape)\n",
        "  y = model.predict(pic_np)\n",
        "  print(\"0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\")\n",
        "  print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAHwUlEQVR4nAXBaYicZwEA4Pf+zvnm\nntkr083dZEtTY1tNWlAEWxWqKBQE9Z9gBY9Si0jRH/4qYlGhCkLRWpGq9aAqaSu1NGq3EXM0aWKa\nTbrJZmd3Z3Z2Zva7j/d7D58HHiaVLKOa27KglTS0bVE/FtR9CLPpYZUD2WCjfJMYTr80uihEJokk\n0YJxQVOKR2VFbDWcnVOfHtxe2Ds76d9vDQayWCCi935mhAkqtITz2NC4nha5MtTQssWBm516Hswm\nt0Lzzrsv5WVeHO+qfVs7fbZZK7P6BH7NvbgVTXRUb6m090jABt1/wcNbB+mzRoGMT443G7fH98/N\nJSBYsS615lZn4aT+8uN5eXrPqScs9ZWnosrNx/2ZqQ2d2/XpqLS1296wIvOBorX/QSJYd62FSp4w\nnLy4PHKIeeHsZO3zar8dXdo476q5BRkvgIhdbVZWzJfKmPfMsOcQOH0jqJgv/WBeADm8XvnNQxs9\nm4s+A2cfTLroylxQ3eO3g1tf/OUH07caNpnC1c3+pLLlUHNjYb6PTzzX+3AbnX9TvJwcJWyNho2i\nE0MfdQ8k4Xfn3/nEJoE/H1/OHcZrPtZWr/L6yU9RQabmO+dW/3NvUW5UkybH2Clw9+gfnr5vU8w3\n4QJImahEWZNNWOPI7JcJUDlNE3n59dUPTAYgSZpA53WcedVvzFlLVw4QwC3pxopEgMTA+EyIDRkj\nBHvI/vfqiVFpgMyQzXx0Ilt47clw0rqF0iwLx4nkCY/wwbsnOIMaQiQHZfPowguzUaIBhzHavxr7\ny+fnhiIgEgsildC4VICfZKpaCJJbILejRXc6pAJlytLmqFlEvZkLH4kXkVYSYYYpMGl9fj21FAcI\nJ4rkTdO6u2aIFFBqCivTw+Rpff26QEBjATXWsnTtJxfTUhoAMbft2JrajSO20KYSUjkQeCqp+bVt\nVEIoCs0RpbW7JqYui5yWsNCQKsSqugcyYIjNQYnkOAn+1hJjpITGMJV2fV/zPKxiUHck3wh2MqVF\nSazOUn1aWBXzpmmWQfnbU7XjSMOcUEYLEQT3vXDiJ1ujndGw0Qjx0CS7QbDiIANNmaQRwimbE++s\nIQZ0Xjhxoval3176ixgk4eaPvvPZX4ma6DbMnh43UCmR1tuhgzP+11spQoJgVFQ8ucx+/8zH4aAt\n+1n8xJcufB+vEcvJi5onvKBqU5W5RrkdHEQSKAiLXOT1tZ899Uh/RIvtdu/VP7Fv8i3qiIXRFNAx\n2kHab5bS3ov+CS2tUUlI4nZvfzW9YT73arFSfeXIRvAoq7Fdb/vFcSPmZiZptpcJ5nVa0JVYclOY\n5Oiez3H5sX4Czy7vtO3i799KllK5snK9o/pThxrcaRTV2DgOLU0EJ7au6d8V8I4g3Jjpz6wVoySf\nzO7v9vPlS1EzzwsMHFabeLPePIEKFxQJtlvsOuCipNObJ8N5hPMFzw8Clx+9arjG0uXAy2WtU8r3\nIVJmBmxYt1TJ2LVLb2Tt9tvtjrc4V08dw7NafZOS2eQQTVMEZSV2FEIcw4TCHM+GF5dv/Pmx1f6t\ndIotIxRl4e/sJHpvB3r2HYCqW8zQNIWWwBBBpxKbPw7cK+fg5gOtxmKBYay1L9T/oh3u4pmRv7HF\natprYkgAKUlhF8kRGQNj4dgVh0I3lkFRi7QgGRkUhpoc8o0pQZWyOXEJAQoBnXT1VLKlr9u9kwTh\n0IgFHlqptYtDZtqb9pkO0zUeIMA0RgBxQiphmx2r/PSO4bu/9hugqkldesriSQJ6iJKKOd42YxLx\nzM1ipAEFhaJeY79cdp//4eQUNyyNs2opFZq1KQAw3DSqK4WRV2sFnPEQVAJi2FTiCyp//s2VZx59\nReYIWtCBHPEMpHeGBlsfMMawqIGRzwmndmLCJk7Y5JnL92SXrlYjpA1Dq0opdiLvvbsQpgFIKxmv\n0mE3nyEmKNs5ltRNRhPymj93D5PaLJEpBeJsfIb9QodUlkyaFkdkUvMRliRhVpuPnT2n/3iNMOxI\nnggCILFBnM7XogJVFaSENUppm2hICqRRYfpBbsGHzx+c5UZGdmo0j1VoFsHujN8Mu1MIbOSJ1oRr\nbhAIS8Q2CcLjRbvNK0DFGc6UMMd6a3zDrgZTtI2Zivco7Q2pPWkSpW3GwNCjehpZ3InTIpRoyxIp\nviGyo3khgFIm6zoCDaAsiwSaJSV22FvzDjy8n5eE9sPt+aHBnR0xTZfgGT3giOh2k64XMG+oqQer\nOqqYDJTCfe4sMP3ML0GM4BTYE95V7x4YxJGR2C2XTznEmPECelZMOpstszCG3zu3Q10/h4bkHsyq\nvPePe7M3Sydvzt9cuEqZRbVF+/Cj52BEXcPFXhndNh9z3oJ2wA3tzPCiuSH9a0UDdhPct5SwGal7\nGzBbP0xcf+5QP7nrvTGwH+puuVMzgpWqM51JNt72pggaCcrrSTvwP8QNgPhibBRuUpKFdZ/J6JU5\nm3d8x8nHRRKe/q/SmSgiqjD1lNcYBckKUiWJKg1uz7ennFObHe90hsykjc64Uh7Xpu+4KE4Mh7tx\n7EiSInR+zMC1LXHaF/s6xwwvOm1VvFpjxkgZAmdNwnBoWDlDpo8oMlodC505vM7ddYe1rg7jC/e6\njWdpMAd2R8jsQDhCQogSo3apNBBA6ms3+P8BNjNoNnhNDhkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48 at 0x7FACA5BBC668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5AAzrfWFHGAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5450a033-4373-4e4e-ce27-c7df896f16d9"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2LmFcuMmHfbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "501e112b-6432-4e48-e550-b9a94dd29362"
      },
      "cell_type": "code",
      "source": [
        "celebanger = Image.open(\"celeb_fer1.jpg\")\n",
        "predict_emotion(model, celebanger)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 48, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-edcd21ba8eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceleb_img_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceleb_img_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1064\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking : expected image_array_input to have 4 dimensions, but got array with shape (48, 48, 1)"
          ]
        }
      ]
    }
  ]
}