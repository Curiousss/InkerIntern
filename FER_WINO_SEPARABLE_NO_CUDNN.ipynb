{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER_WINO_SEPARABLE_NO_CUDNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Curiousss/InkerIntern/blob/master/FER_WINO_SEPARABLE_NO_CUDNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Q9eNowMGaO_J",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "394b813f-8d2a-47db-db98-1e5850a3e2e6"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-576cdbae-2822-45dc-96fd-c3a51c31f63f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-576cdbae-2822-45dc-96fd-c3a51c31f63f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving baddata.txt to baddata.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BEb9SWJUV8T2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5f8c58f-25a4-46fd-c63a-b6f7a7b075ef"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ldEdUzQbuQIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "d6a31d84-92c8-46b5-ca50-81bfc578b750"
      },
      "cell_type": "code",
      "source": [
        "!tar xvf fer2013.tar\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fer2013/fer2013.csv\n",
            "fer2013/README\n",
            "fer2013/fer2013.bib\n",
            "fer2013/\n",
            "datalab  fer2013  fer2013.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dTyUIGDeuAQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5750261b-4596-4957-b1b0-4e5bf7fcc979"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D, InputLayer\n",
        "from keras.layers import Convolution2D, SeparableConv2D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OqJCQeGxhq4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 48, 48\n",
        "batch_size = 128\n",
        "classes = 7\n",
        "epoch = 100\n",
        "img_channels = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sq7nNsVmhsYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "f = open('fer2013/fer2013.csv')\n",
        "csv_f = csv.reader(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQSDhHZ3tKqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "val_x =[]\n",
        "val_y =[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eWmuGFqNF5Ds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ToBeRemovedTrainingData = []\n",
        "with open(\"baddata.txt\", \"r\") as text:\n",
        "  for line in text:\n",
        "    ToBeRemovedTrainingData.append(int(line))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HmmgpkTpiWyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num=0\n",
        "for row in csv_f:\n",
        "  num = num +1\n",
        "  if num in ToBeRemovedTrainingData or num==1:\n",
        "    continue\n",
        "  #print(row)\n",
        "  #print(num)\n",
        "  temp_list = []\n",
        "  for pixel in row[1].split( ):\n",
        "    temp_list.append(int(pixel))\n",
        "\n",
        "  if str(row[2]) == \"Training\":\n",
        "    train_y.append(int(row[0]))\n",
        "    train_x.append(temp_list) \n",
        "  elif str(row[2]) == \"PublicTest\":\n",
        "    val_y.append(int(row[0]))\n",
        "    val_x.append(temp_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6rDJXl4rUKS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = np.asarray(train_x)\n",
        "train_y = np.asarray(train_y)\n",
        "val_x = np.asarray(val_x)\n",
        "val_y = np.asarray(val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lmXwV3InrVsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = train_x.reshape(train_x.shape[0], 48, 48)\n",
        "train_x = train_x.reshape(train_x.shape[0], 48, 48, 1 )\n",
        "train_y = np_utils.to_categorical(train_y, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3iZUfL1ztRu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_x = val_x.reshape(val_x.shape[0], 48, 48)\n",
        "val_x = val_x.reshape(val_x.shape[0], 48, 48, 1)\n",
        "val_y = np_utils.to_categorical(val_y, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FAWueVKKI0CR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "bdc568c0-9e1b-499a-e3b7-15e91e5b1521"
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "#print(train_x.shape)\n",
        "\n",
        "showimg = train_x[1].reshape(48,48)\n",
        "img = Image.fromarray(showimg.astype('uint8'))\n",
        "from IPython.display import display\n",
        "display(img)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAHO0lEQVR4nAXB2Y4cVxkA4LP8Z6ut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\nFH15IbD7P4euDm5pw/eMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48 at 0x7F0E65C00FD0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bkb-p1BXzBrI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = train_x.astype('float32')\n",
        "train_x = train_x / 255.0\n",
        "val_x = val_x.astype('float32')\n",
        "val_x = val_x / 255.0\n",
        "train_x = train_x - 0.5\n",
        "train_x = train_x * 2\n",
        "val_x = val_x - 0.5\n",
        "val_x = val_x * 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMKS1KOEGsB3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = (img_rows, img_cols, img_channels)\n",
        "model = Sequential()\n",
        "model.add(SeparableConv2D(filters=64, kernel_size=(3, 3), padding='same',\n",
        "                            name='image_array', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=512, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=512, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "#model.add(Flatten())\n",
        "'''\n",
        "model.add(Dense(1024))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(2048))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "'''\n",
        "model.add(InputLayer(input_shape=(3, 3, 1024)))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "\n",
        "model.add(Dense(1024))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(7))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRsZspcA0uxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1454
        },
        "outputId": "6791d992-92ec-4353-d472-853ff3592c09"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "image_array (SeparableConv2D (None, 48, 48, 64)        153       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_1 (Separabl (None, 48, 48, 64)        5760      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_2 (Separabl (None, 24, 24, 128)       9920      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_3 (Separabl (None, 24, 24, 128)       19712     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_4 (Separabl (None, 12, 12, 256)       36224     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_5 (Separabl (None, 12, 12, 256)       72192     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_6 (Separabl (None, 6, 6, 512)         137984    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_7 (Separabl (None, 6, 6, 512)         275456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "input_1 (InputLayer)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 3591      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 568,672\n",
            "Trainable params: 564,832\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hy0FyCcc2li0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "filepath='Model.best.hdf5'\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZYe0RPXn4O_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('Model.best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJiUe6bEgjHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5445
        },
        "outputId": "17bc8cb0-eef7-4d05-f37d-58dfc1444876"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(train_x)\n",
        "\n",
        "model.fit_generator(datagen.flow(train_x, train_y,\n",
        "                    batch_size=batch_size),\n",
        "                    steps_per_epoch=(train_x.shape[0]/batch_size),\n",
        "                    epochs=150,\n",
        "                    validation_data=(val_x, val_y),\n",
        "                    callbacks=[checkpointer])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "224/223 [==============================] - 55s 247ms/step - loss: 0.7157 - acc: 0.7325 - val_loss: 1.0062 - val_acc: 0.6572\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.67392\n",
            "Epoch 2/150\n",
            "224/223 [==============================] - 55s 246ms/step - loss: 0.7097 - acc: 0.7322 - val_loss: 1.0382 - val_acc: 0.6544\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.67392\n",
            "Epoch 3/150\n",
            " 34/223 [===>..........................] - ETA: 44s - loss: 0.6826 - acc: 0.7445"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 246ms/step - loss: 0.7021 - acc: 0.7365 - val_loss: 1.0433 - val_acc: 0.6611\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.67392\n",
            "Epoch 4/150\n",
            "224/223 [==============================] - 55s 246ms/step - loss: 0.7027 - acc: 0.7361 - val_loss: 1.0719 - val_acc: 0.6563\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.67392\n",
            "Epoch 5/150\n",
            " 53/223 [======>.......................] - ETA: 39s - loss: 0.6936 - acc: 0.7405"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 246ms/step - loss: 0.7033 - acc: 0.7355 - val_loss: 1.0541 - val_acc: 0.6611\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.67392\n",
            "Epoch 6/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6997 - acc: 0.7393 - val_loss: 1.0439 - val_acc: 0.6589\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.67392\n",
            "Epoch 7/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6873 - acc: 0.7391"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.7017 - acc: 0.7368 - val_loss: 1.0518 - val_acc: 0.6630\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.67392\n",
            "Epoch 8/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.7030 - acc: 0.7390 - val_loss: 1.0267 - val_acc: 0.6597\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.67392\n",
            "Epoch 9/150\n",
            " 57/223 [======>.......................] - ETA: 39s - loss: 0.6708 - acc: 0.7479"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6964 - acc: 0.7384 - val_loss: 1.0254 - val_acc: 0.6628\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.67392\n",
            "Epoch 10/150\n",
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6915 - acc: 0.7416 - val_loss: 1.0595 - val_acc: 0.6636\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.67392\n",
            "Epoch 11/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6906 - acc: 0.7425"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6922 - acc: 0.7408 - val_loss: 1.0535 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.67392\n",
            "Epoch 12/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6913 - acc: 0.7420 - val_loss: 1.0594 - val_acc: 0.6614\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.67392\n",
            "Epoch 13/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6870 - acc: 0.7451"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6832 - acc: 0.7468 - val_loss: 1.0929 - val_acc: 0.6600\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.67392\n",
            "Epoch 14/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6910 - acc: 0.7420 - val_loss: 1.0502 - val_acc: 0.6628\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.67392\n",
            "Epoch 15/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6650 - acc: 0.7464"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6946 - acc: 0.7401 - val_loss: 1.0697 - val_acc: 0.6630\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.67392\n",
            "Epoch 16/150\n",
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6905 - acc: 0.7433 - val_loss: 1.0560 - val_acc: 0.6614\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.67392\n",
            "Epoch 17/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6808 - acc: 0.7437"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6865 - acc: 0.7442 - val_loss: 1.0286 - val_acc: 0.6577\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.67392\n",
            "Epoch 18/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6805 - acc: 0.7445 - val_loss: 1.0685 - val_acc: 0.6611\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.67392\n",
            "Epoch 19/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6692 - acc: 0.7525"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6809 - acc: 0.7452 - val_loss: 1.0314 - val_acc: 0.6664\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.67392\n",
            "Epoch 20/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6820 - acc: 0.7432 - val_loss: 1.0545 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.67392\n",
            "Epoch 21/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6580 - acc: 0.7554"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6799 - acc: 0.7448 - val_loss: 1.0384 - val_acc: 0.6661\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.67392\n",
            "Epoch 22/150\n",
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6772 - acc: 0.7467 - val_loss: 1.0789 - val_acc: 0.6603\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.67392\n",
            "Epoch 23/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6674 - acc: 0.7490"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 246ms/step - loss: 0.6725 - acc: 0.7461 - val_loss: 1.0622 - val_acc: 0.6614\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.67392\n",
            "Epoch 24/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6680 - acc: 0.7504 - val_loss: 1.0909 - val_acc: 0.6536\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.67392\n",
            "Epoch 25/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6650 - acc: 0.7464"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 243ms/step - loss: 0.6778 - acc: 0.7446 - val_loss: 1.0525 - val_acc: 0.6630\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.67392\n",
            "Epoch 26/150\n",
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6752 - acc: 0.7449 - val_loss: 1.0798 - val_acc: 0.6550\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.67392\n",
            "Epoch 27/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6550 - acc: 0.7531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 243ms/step - loss: 0.6675 - acc: 0.7519 - val_loss: 1.0817 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.67392\n",
            "Epoch 28/150\n",
            "224/223 [==============================] - 55s 243ms/step - loss: 0.6701 - acc: 0.7499 - val_loss: 1.0704 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.67392\n",
            "Epoch 29/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6496 - acc: 0.7588"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6609 - acc: 0.7534 - val_loss: 1.0679 - val_acc: 0.6575\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.67392\n",
            "Epoch 30/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6612 - acc: 0.7493 - val_loss: 1.0748 - val_acc: 0.6597\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.67392\n",
            "Epoch 31/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6596 - acc: 0.7575"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 54s 243ms/step - loss: 0.6595 - acc: 0.7536 - val_loss: 1.0658 - val_acc: 0.6703\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.67392\n",
            "Epoch 32/150\n",
            "224/223 [==============================] - 55s 246ms/step - loss: 0.6610 - acc: 0.7545 - val_loss: 1.0559 - val_acc: 0.6686\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.67392\n",
            "Epoch 33/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6475 - acc: 0.7555"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 246ms/step - loss: 0.6491 - acc: 0.7582 - val_loss: 1.0894 - val_acc: 0.6636\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.67392\n",
            "Epoch 34/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6531 - acc: 0.7539 - val_loss: 1.0731 - val_acc: 0.6664\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.67392\n",
            "Epoch 35/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6684 - acc: 0.7536"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6564 - acc: 0.7573 - val_loss: 1.1664 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.67392\n",
            "Epoch 36/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6533 - acc: 0.7533 - val_loss: 1.0973 - val_acc: 0.6619\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.67392\n",
            "Epoch 37/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6280 - acc: 0.7619"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6495 - acc: 0.7565 - val_loss: 1.0674 - val_acc: 0.6709\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.67392\n",
            "Epoch 38/150\n",
            "224/223 [==============================] - 54s 243ms/step - loss: 0.6460 - acc: 0.7574 - val_loss: 1.1059 - val_acc: 0.6577\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.67392\n",
            "Epoch 39/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6381 - acc: 0.7595"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6483 - acc: 0.7571 - val_loss: 1.0973 - val_acc: 0.6580\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.67392\n",
            "Epoch 40/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6404 - acc: 0.7600 - val_loss: 1.1285 - val_acc: 0.6519\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.67392\n",
            "Epoch 41/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6314 - acc: 0.7571"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6460 - acc: 0.7550 - val_loss: 1.0436 - val_acc: 0.6656\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.67392\n",
            "Epoch 42/150\n",
            "224/223 [==============================] - 54s 243ms/step - loss: 0.6395 - acc: 0.7606 - val_loss: 1.0984 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.67392\n",
            "Epoch 43/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6363 - acc: 0.7646"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6459 - acc: 0.7585 - val_loss: 1.0955 - val_acc: 0.6558\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.67392\n",
            "Epoch 44/150\n",
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6427 - acc: 0.7579 - val_loss: 1.0973 - val_acc: 0.6664\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.67392\n",
            "Epoch 45/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6189 - acc: 0.7669"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6393 - acc: 0.7610 - val_loss: 1.0819 - val_acc: 0.6572\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.67392\n",
            "Epoch 46/150\n",
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6429 - acc: 0.7588 - val_loss: 1.0974 - val_acc: 0.6586\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.67392\n",
            "Epoch 47/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6249 - acc: 0.7637"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6344 - acc: 0.7616 - val_loss: 1.0873 - val_acc: 0.6630\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.67392\n",
            "Epoch 48/150\n",
            "224/223 [==============================] - 55s 245ms/step - loss: 0.6322 - acc: 0.7648 - val_loss: 1.1220 - val_acc: 0.6533\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.67392\n",
            "Epoch 49/150\n",
            " 56/223 [======>.......................] - ETA: 39s - loss: 0.6123 - acc: 0.7694"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 55s 244ms/step - loss: 0.6260 - acc: 0.7664 - val_loss: 1.1198 - val_acc: 0.6541\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.67392\n",
            "Epoch 50/150\n",
            "224/223 [==============================] - 55s 246ms/step - loss: 0.6253 - acc: 0.7633 - val_loss: 1.1339 - val_acc: 0.6536\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.67392\n",
            "Epoch 51/150\n",
            " 36/223 [===>..........................] - ETA: 44s - loss: 0.5979 - acc: 0.7745"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-535f289dfc31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     callbacks=[checkpointer])\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "u88FL_-58w-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8292
        },
        "outputId": "2d351bc0-a01e-48a2-b6c2-fde909f1fa21"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(train_x)\n",
        "\n",
        "model.fit_generator(datagen.flow(train_x, train_y,\n",
        "                    batch_size=batch_size),\n",
        "                    steps_per_epoch=(train_x.shape[0]/batch_size),\n",
        "                    epochs=150,\n",
        "                    validation_data=(val_x, val_y),\n",
        "                    callbacks=[checkpointer])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "224/223 [==============================] - 86s 385ms/step - loss: 1.7794 - acc: 0.2794 - val_loss: 2.4532 - val_acc: 0.2884\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.28842, saving model to Model.best.hdf5\n",
            "Epoch 2/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 1.6080 - acc: 0.3673 - val_loss: 1.7210 - val_acc: 0.4137\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.28842 to 0.41367, saving model to Model.best.hdf5\n",
            "Epoch 3/150\n",
            " 15/223 [=>............................] - ETA: 1:15 - loss: 1.5599 - acc: 0.3990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 1.4907 - acc: 0.4229 - val_loss: 1.5570 - val_acc: 0.4379\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.41367 to 0.43794, saving model to Model.best.hdf5\n",
            "Epoch 4/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 1.4041 - acc: 0.4642 - val_loss: 1.7731 - val_acc: 0.4391\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.43794 to 0.43905, saving model to Model.best.hdf5\n",
            "Epoch 5/150\n",
            " 27/223 [==>...........................] - ETA: 1:10 - loss: 1.3778 - acc: 0.4763"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 1.3504 - acc: 0.4871 - val_loss: 1.3599 - val_acc: 0.5043\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.43905 to 0.50432, saving model to Model.best.hdf5\n",
            "Epoch 6/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 1.3131 - acc: 0.4957 - val_loss: 1.4018 - val_acc: 0.4962\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.50432\n",
            "Epoch 7/150\n",
            " 31/223 [===>..........................] - ETA: 1:09 - loss: 1.2866 - acc: 0.5149"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 1.2762 - acc: 0.5168 - val_loss: 1.3137 - val_acc: 0.5180\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.50432 to 0.51799, saving model to Model.best.hdf5\n",
            "Epoch 8/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 1.2479 - acc: 0.5228 - val_loss: 1.2157 - val_acc: 0.5523\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.51799 to 0.55230, saving model to Model.best.hdf5\n",
            "Epoch 9/150\n",
            " 29/223 [==>...........................] - ETA: 1:10 - loss: 1.2225 - acc: 0.5380"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 1.2266 - acc: 0.5320 - val_loss: 1.2089 - val_acc: 0.5473\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.55230\n",
            "Epoch 10/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 1.2108 - acc: 0.5395 - val_loss: 1.3121 - val_acc: 0.5191\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.55230\n",
            "Epoch 11/150\n",
            " 51/223 [=====>........................] - ETA: 1:02 - loss: 1.2068 - acc: 0.5415"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 1.1917 - acc: 0.5507 - val_loss: 1.1733 - val_acc: 0.5646\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.55230 to 0.56457, saving model to Model.best.hdf5\n",
            "Epoch 12/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 1.1746 - acc: 0.5527 - val_loss: 1.1517 - val_acc: 0.5702\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.56457 to 0.57015, saving model to Model.best.hdf5\n",
            "Epoch 13/150\n",
            " 31/223 [===>..........................] - ETA: 1:09 - loss: 1.1400 - acc: 0.5658"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 1.1607 - acc: 0.5592 - val_loss: 1.1797 - val_acc: 0.5640\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.57015\n",
            "Epoch 14/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 1.1455 - acc: 0.5695 - val_loss: 1.1686 - val_acc: 0.5693\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.57015\n",
            "Epoch 15/150\n",
            " 51/223 [=====>........................] - ETA: 1:01 - loss: 1.1485 - acc: 0.5664"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 1.1332 - acc: 0.5728 - val_loss: 1.1252 - val_acc: 0.5902\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.57015 to 0.59024, saving model to Model.best.hdf5\n",
            "Epoch 16/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 1.1261 - acc: 0.5734 - val_loss: 1.1983 - val_acc: 0.5601\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.59024\n",
            "Epoch 17/150\n",
            " 34/223 [===>..........................] - ETA: 1:08 - loss: 1.1190 - acc: 0.5788"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 1.1146 - acc: 0.5765 - val_loss: 1.2598 - val_acc: 0.5364\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.59024\n",
            "Epoch 18/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 1.1041 - acc: 0.5827 - val_loss: 1.1459 - val_acc: 0.5674\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.59024\n",
            "Epoch 19/150\n",
            " 52/223 [=====>........................] - ETA: 1:02 - loss: 1.0829 - acc: 0.5859"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 1.0933 - acc: 0.5851 - val_loss: 1.1354 - val_acc: 0.5763\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.59024\n",
            "Epoch 20/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 1.0765 - acc: 0.5912 - val_loss: 1.2312 - val_acc: 0.5570\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.59024\n",
            "Epoch 21/150\n",
            " 55/223 [======>.......................] - ETA: 1:00 - loss: 1.1000 - acc: 0.5882"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 1.0703 - acc: 0.5986 - val_loss: 1.0925 - val_acc: 0.6036\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.59024 to 0.60363, saving model to Model.best.hdf5\n",
            "Epoch 22/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 1.0646 - acc: 0.5955 - val_loss: 1.0519 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.60363 to 0.60976, saving model to Model.best.hdf5\n",
            "Epoch 23/150\n",
            " 32/223 [===>..........................] - ETA: 1:09 - loss: 1.0315 - acc: 0.6096"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 1.0501 - acc: 0.6026 - val_loss: 1.1823 - val_acc: 0.5741\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.60976\n",
            "Epoch 24/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 1.0464 - acc: 0.6033 - val_loss: 1.0558 - val_acc: 0.6089\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.60976\n",
            "Epoch 25/150\n",
            " 52/223 [=====>........................] - ETA: 1:01 - loss: 1.0262 - acc: 0.6109"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 1.0343 - acc: 0.6095 - val_loss: 1.1343 - val_acc: 0.5902\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.60976\n",
            "Epoch 26/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 1.0307 - acc: 0.6111 - val_loss: 1.1273 - val_acc: 0.5930\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.60976\n",
            "Epoch 27/150\n",
            " 55/223 [======>.......................] - ETA: 1:00 - loss: 1.0056 - acc: 0.6241"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 1.0197 - acc: 0.6160 - val_loss: 1.1440 - val_acc: 0.5992\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.60976\n",
            "Epoch 28/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 1.0118 - acc: 0.6194 - val_loss: 1.1500 - val_acc: 0.5738\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.60976\n",
            "Epoch 29/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.9910 - acc: 0.6258"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 1.0031 - acc: 0.6220 - val_loss: 1.0682 - val_acc: 0.6056\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.60976\n",
            "Epoch 30/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9947 - acc: 0.6244 - val_loss: 1.0655 - val_acc: 0.6134\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.60976 to 0.61339, saving model to Model.best.hdf5\n",
            "Epoch 31/150\n",
            " 52/223 [=====>........................] - ETA: 1:02 - loss: 0.9719 - acc: 0.6330"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9968 - acc: 0.6250 - val_loss: 1.0909 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.61339\n",
            "Epoch 32/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9859 - acc: 0.6293 - val_loss: 1.0337 - val_acc: 0.6229\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.61339 to 0.62287, saving model to Model.best.hdf5\n",
            "Epoch 33/150\n",
            " 51/223 [=====>........................] - ETA: 1:02 - loss: 0.9621 - acc: 0.6406"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9773 - acc: 0.6325 - val_loss: 1.0958 - val_acc: 0.6056\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.62287\n",
            "Epoch 34/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.9697 - acc: 0.6347 - val_loss: 1.0862 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.62287\n",
            "Epoch 35/150\n",
            " 55/223 [======>.......................] - ETA: 1:00 - loss: 0.9668 - acc: 0.6410"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9674 - acc: 0.6387 - val_loss: 1.0431 - val_acc: 0.6218\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.62287\n",
            "Epoch 36/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9561 - acc: 0.6443 - val_loss: 1.0691 - val_acc: 0.6137\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.62287\n",
            "Epoch 37/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.9361 - acc: 0.6525"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9506 - acc: 0.6430 - val_loss: 1.0150 - val_acc: 0.6279\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.62287 to 0.62789, saving model to Model.best.hdf5\n",
            "Epoch 38/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9437 - acc: 0.6459 - val_loss: 1.0650 - val_acc: 0.6262\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.62789\n",
            "Epoch 39/150\n",
            " 35/223 [===>..........................] - ETA: 1:07 - loss: 0.9081 - acc: 0.6592"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9405 - acc: 0.6459 - val_loss: 1.0005 - val_acc: 0.6192\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.62789\n",
            "Epoch 40/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9325 - acc: 0.6509 - val_loss: 1.1211 - val_acc: 0.5813\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.62789\n",
            "Epoch 41/150\n",
            " 52/223 [=====>........................] - ETA: 1:01 - loss: 0.9180 - acc: 0.6541"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9264 - acc: 0.6524 - val_loss: 1.0737 - val_acc: 0.6089\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.62789\n",
            "Epoch 42/150\n",
            "224/223 [==============================] - 83s 373ms/step - loss: 0.9183 - acc: 0.6575 - val_loss: 1.0404 - val_acc: 0.6276\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.62789\n",
            "Epoch 43/150\n",
            " 55/223 [======>.......................] - ETA: 1:00 - loss: 0.8939 - acc: 0.6696"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9193 - acc: 0.6587 - val_loss: 1.0214 - val_acc: 0.6254\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.62789\n",
            "Epoch 44/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9101 - acc: 0.6627 - val_loss: 1.0284 - val_acc: 0.6285\n",
            "\n",
            "Epoch 00044: val_acc improved from 0.62789 to 0.62845, saving model to Model.best.hdf5\n",
            "Epoch 45/150\n",
            " 51/223 [=====>........................] - ETA: 1:01 - loss: 0.8927 - acc: 0.6611"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.9017 - acc: 0.6613 - val_loss: 1.0102 - val_acc: 0.6371\n",
            "\n",
            "Epoch 00045: val_acc improved from 0.62845 to 0.63710, saving model to Model.best.hdf5\n",
            "Epoch 46/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.8978 - acc: 0.6640 - val_loss: 1.0448 - val_acc: 0.6265\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.63710\n",
            "Epoch 47/150\n",
            " 34/223 [===>..........................] - ETA: 1:08 - loss: 0.8772 - acc: 0.6774"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 0.9009 - acc: 0.6628 - val_loss: 1.0155 - val_acc: 0.6282\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.63710\n",
            "Epoch 48/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8912 - acc: 0.6686 - val_loss: 1.0149 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.63710\n",
            "Epoch 49/150\n",
            " 52/223 [=====>........................] - ETA: 1:02 - loss: 0.8589 - acc: 0.6804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.8849 - acc: 0.6713 - val_loss: 1.0623 - val_acc: 0.6215\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.63710\n",
            "Epoch 50/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.8731 - acc: 0.6710 - val_loss: 1.0602 - val_acc: 0.6245\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.63710\n",
            "Epoch 51/150\n",
            " 55/223 [======>.......................] - ETA: 1:00 - loss: 0.8416 - acc: 0.6841"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.8705 - acc: 0.6750 - val_loss: 1.0145 - val_acc: 0.6377\n",
            "\n",
            "Epoch 00051: val_acc improved from 0.63710 to 0.63766, saving model to Model.best.hdf5\n",
            "Epoch 52/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.8711 - acc: 0.6751 - val_loss: 1.0284 - val_acc: 0.6351\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.63766\n",
            "Epoch 53/150\n",
            " 35/223 [===>..........................] - ETA: 1:08 - loss: 0.8380 - acc: 0.6859"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.8602 - acc: 0.6814 - val_loss: 1.0225 - val_acc: 0.6254\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.63766\n",
            "Epoch 54/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8557 - acc: 0.6794 - val_loss: 1.0716 - val_acc: 0.6106\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.63766\n",
            "Epoch 55/150\n",
            " 52/223 [=====>........................] - ETA: 1:01 - loss: 0.8299 - acc: 0.6935"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.8522 - acc: 0.6828 - val_loss: 1.0781 - val_acc: 0.6301\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.63766\n",
            "Epoch 56/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8426 - acc: 0.6843 - val_loss: 1.0279 - val_acc: 0.6290\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.63766\n",
            "Epoch 57/150\n",
            " 55/223 [======>.......................] - ETA: 1:00 - loss: 0.8103 - acc: 0.6963"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8438 - acc: 0.6853 - val_loss: 1.0631 - val_acc: 0.6324\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.63766\n",
            "Epoch 58/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8397 - acc: 0.6873 - val_loss: 1.0632 - val_acc: 0.6237\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.63766\n",
            "Epoch 59/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.8267 - acc: 0.6948"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8409 - acc: 0.6852 - val_loss: 1.0142 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00059: val_acc improved from 0.63766 to 0.64630, saving model to Model.best.hdf5\n",
            "Epoch 60/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8311 - acc: 0.6926 - val_loss: 1.0329 - val_acc: 0.6232\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.64630\n",
            "Epoch 61/150\n",
            " 35/223 [===>..........................] - ETA: 1:06 - loss: 0.8083 - acc: 0.7048"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8234 - acc: 0.6933 - val_loss: 1.0559 - val_acc: 0.6282\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.64630\n",
            "Epoch 62/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8171 - acc: 0.6957 - val_loss: 1.0215 - val_acc: 0.6413\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.64630\n",
            "Epoch 63/150\n",
            " 52/223 [=====>........................] - ETA: 1:02 - loss: 0.8064 - acc: 0.7040"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8174 - acc: 0.6989 - val_loss: 1.0291 - val_acc: 0.6438\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.64630\n",
            "Epoch 64/150\n",
            "224/223 [==============================] - 83s 373ms/step - loss: 0.8185 - acc: 0.6962 - val_loss: 1.0293 - val_acc: 0.6407\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.64630\n",
            "Epoch 65/150\n",
            " 55/223 [======>.......................] - ETA: 1:00 - loss: 0.7799 - acc: 0.7063"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 0.8072 - acc: 0.6991 - val_loss: 0.9926 - val_acc: 0.6446\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.64630\n",
            "Epoch 66/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.7999 - acc: 0.7025 - val_loss: 1.0042 - val_acc: 0.6449\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.64630\n",
            "Epoch 67/150\n",
            " 56/223 [======>.......................] - ETA: 59s - loss: 0.7873 - acc: 0.7045 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.8074 - acc: 0.6994 - val_loss: 1.0188 - val_acc: 0.6377\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.64630\n",
            "Epoch 68/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.7978 - acc: 0.7035 - val_loss: 1.0349 - val_acc: 0.6396\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.64630\n",
            "Epoch 69/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.8045 - acc: 0.6961"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 0.7979 - acc: 0.7021 - val_loss: 1.0352 - val_acc: 0.6466\n",
            "\n",
            "Epoch 00069: val_acc improved from 0.64630 to 0.64658, saving model to Model.best.hdf5\n",
            "Epoch 70/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.7863 - acc: 0.7057 - val_loss: 1.0575 - val_acc: 0.6377\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.64658\n",
            "Epoch 71/150\n",
            " 35/223 [===>..........................] - ETA: 1:06 - loss: 0.7765 - acc: 0.7130"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.7831 - acc: 0.7084 - val_loss: 1.0278 - val_acc: 0.6499\n",
            "\n",
            "Epoch 00071: val_acc improved from 0.64658 to 0.64993, saving model to Model.best.hdf5\n",
            "Epoch 72/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.7812 - acc: 0.7133 - val_loss: 1.0080 - val_acc: 0.6502\n",
            "\n",
            "Epoch 00072: val_acc improved from 0.64993 to 0.65021, saving model to Model.best.hdf5\n",
            "Epoch 73/150\n",
            " 29/223 [==>...........................] - ETA: 1:10 - loss: 0.7597 - acc: 0.7198"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.7740 - acc: 0.7107 - val_loss: 1.0594 - val_acc: 0.6310\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.65021\n",
            "Epoch 74/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.7697 - acc: 0.7132 - val_loss: 1.1004 - val_acc: 0.6326\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.65021\n",
            "Epoch 75/150\n",
            " 51/223 [=====>........................] - ETA: 1:02 - loss: 0.7552 - acc: 0.7189"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.7651 - acc: 0.7150 - val_loss: 1.0617 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.65021\n",
            "Epoch 76/150\n",
            "224/223 [==============================] - 84s 373ms/step - loss: 0.7623 - acc: 0.7163 - val_loss: 1.0306 - val_acc: 0.6524\n",
            "\n",
            "Epoch 00076: val_acc improved from 0.65021 to 0.65244, saving model to Model.best.hdf5\n",
            "Epoch 77/150\n",
            " 51/223 [=====>........................] - ETA: 1:02 - loss: 0.7573 - acc: 0.7178"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 373ms/step - loss: 0.7662 - acc: 0.7149 - val_loss: 1.0182 - val_acc: 0.6441\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.65244\n",
            "Epoch 78/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.7616 - acc: 0.7176 - val_loss: 1.0524 - val_acc: 0.6505\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.65244\n",
            "Epoch 79/150\n",
            " 55/223 [======>.......................] - ETA: 1:01 - loss: 0.7328 - acc: 0.7291"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7528 - acc: 0.7197 - val_loss: 1.0359 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.65244\n",
            "Epoch 80/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7498 - acc: 0.7223 - val_loss: 1.0658 - val_acc: 0.6343\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.65244\n",
            "Epoch 81/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.7259 - acc: 0.7365"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7487 - acc: 0.7218 - val_loss: 1.0571 - val_acc: 0.6338\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.65244\n",
            "Epoch 82/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7452 - acc: 0.7246 - val_loss: 1.0376 - val_acc: 0.6616\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.65244 to 0.66165, saving model to Model.best.hdf5\n",
            "Epoch 83/150\n",
            " 52/223 [=====>........................] - ETA: 1:01 - loss: 0.7068 - acc: 0.7368"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7412 - acc: 0.7248 - val_loss: 1.0477 - val_acc: 0.6474\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.66165\n",
            "Epoch 84/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7420 - acc: 0.7247 - val_loss: 1.0325 - val_acc: 0.6536\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.66165\n",
            "Epoch 85/150\n",
            " 55/223 [======>.......................] - ETA: 1:01 - loss: 0.7129 - acc: 0.7337"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7284 - acc: 0.7303 - val_loss: 1.1028 - val_acc: 0.6382\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.66165\n",
            "Epoch 86/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7268 - acc: 0.7328 - val_loss: 1.0925 - val_acc: 0.6343\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.66165\n",
            "Epoch 87/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.6906 - acc: 0.7411"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7221 - acc: 0.7328 - val_loss: 0.9977 - val_acc: 0.6516\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.66165\n",
            "Epoch 88/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7264 - acc: 0.7287 - val_loss: 1.0758 - val_acc: 0.6388\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.66165\n",
            "Epoch 89/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.6792 - acc: 0.7496"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7148 - acc: 0.7355 - val_loss: 1.0343 - val_acc: 0.6432\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.66165\n",
            "Epoch 90/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7150 - acc: 0.7347 - val_loss: 1.0796 - val_acc: 0.6541\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.66165\n",
            "Epoch 91/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.7023 - acc: 0.7383"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7091 - acc: 0.7354 - val_loss: 1.0154 - val_acc: 0.6516\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.66165\n",
            "Epoch 92/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.7115 - acc: 0.7353 - val_loss: 1.0267 - val_acc: 0.6502\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.66165\n",
            "Epoch 93/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.6951 - acc: 0.7426"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.7133 - acc: 0.7366 - val_loss: 1.0305 - val_acc: 0.6536\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.66165\n",
            "Epoch 94/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.7071 - acc: 0.7358 - val_loss: 1.0391 - val_acc: 0.6455\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.66165\n",
            "Epoch 95/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.6819 - acc: 0.7529"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6949 - acc: 0.7430 - val_loss: 1.0536 - val_acc: 0.6505\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.66165\n",
            "Epoch 96/150\n",
            "224/223 [==============================] - 84s 374ms/step - loss: 0.6990 - acc: 0.7398 - val_loss: 1.0673 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.66165\n",
            "Epoch 97/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.6739 - acc: 0.7515"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 0.7000 - acc: 0.7410 - val_loss: 1.0495 - val_acc: 0.6533\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.66165\n",
            "Epoch 98/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6941 - acc: 0.7443 - val_loss: 1.0806 - val_acc: 0.6324\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.66165\n",
            "Epoch 99/150\n",
            " 56/223 [======>.......................] - ETA: 1:00 - loss: 0.6727 - acc: 0.7514"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6855 - acc: 0.7460 - val_loss: 1.0418 - val_acc: 0.6421\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.66165\n",
            "Epoch 100/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6886 - acc: 0.7444 - val_loss: 1.0741 - val_acc: 0.6510\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.66165\n",
            "Epoch 101/150\n",
            " 55/223 [======>.......................] - ETA: 1:01 - loss: 0.6517 - acc: 0.7557"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6824 - acc: 0.7468 - val_loss: 1.0815 - val_acc: 0.6446\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.66165\n",
            "Epoch 102/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6798 - acc: 0.7494 - val_loss: 1.0648 - val_acc: 0.6550\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.66165\n",
            "Epoch 103/150\n",
            " 55/223 [======>.......................] - ETA: 1:01 - loss: 0.6514 - acc: 0.7645"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 374ms/step - loss: 0.6716 - acc: 0.7504 - val_loss: 1.0452 - val_acc: 0.6619\n",
            "\n",
            "Epoch 00103: val_acc improved from 0.66165 to 0.66192, saving model to Model.best.hdf5\n",
            "Epoch 104/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6655 - acc: 0.7528 - val_loss: 1.0744 - val_acc: 0.6435\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.66192\n",
            "Epoch 105/150\n",
            " 34/223 [===>..........................] - ETA: 1:09 - loss: 0.6628 - acc: 0.7562"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6709 - acc: 0.7531 - val_loss: 1.0488 - val_acc: 0.6519\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.66192\n",
            "Epoch 106/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6658 - acc: 0.7519 - val_loss: 1.0841 - val_acc: 0.6416\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.66192\n",
            "Epoch 107/150\n",
            " 51/223 [=====>........................] - ETA: 1:02 - loss: 0.6357 - acc: 0.7684"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6602 - acc: 0.7538 - val_loss: 1.0504 - val_acc: 0.6421\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.66192\n",
            "Epoch 108/150\n",
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6611 - acc: 0.7571 - val_loss: 1.0400 - val_acc: 0.6510\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.66192\n",
            "Epoch 109/150\n",
            " 54/223 [======>.......................] - ETA: 1:01 - loss: 0.6419 - acc: 0.7648"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6584 - acc: 0.7569 - val_loss: 1.0655 - val_acc: 0.6488\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.66192\n",
            "Epoch 110/150\n",
            "224/223 [==============================] - 84s 376ms/step - loss: 0.6494 - acc: 0.7584 - val_loss: 1.0699 - val_acc: 0.6616\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.66192\n",
            "Epoch 111/150\n",
            " 55/223 [======>.......................] - ETA: 1:00 - loss: 0.6250 - acc: 0.7683"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6492 - acc: 0.7589 - val_loss: 1.0594 - val_acc: 0.6536\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.66192\n",
            "Epoch 112/150\n",
            "224/223 [==============================] - 84s 376ms/step - loss: 0.6548 - acc: 0.7594 - val_loss: 1.0937 - val_acc: 0.6522\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.66192\n",
            "Epoch 113/150\n",
            " 55/223 [======>.......................] - ETA: 1:01 - loss: 0.6465 - acc: 0.7652"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 84s 375ms/step - loss: 0.6468 - acc: 0.7627 - val_loss: 1.1198 - val_acc: 0.6410\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.66192\n",
            "Epoch 114/150\n",
            " 51/223 [=====>........................] - ETA: 1:02 - loss: 0.6124 - acc: 0.7774"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WMaPXKT8FSGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "a0d5cdf5-008e-4b13-cf13-11adae5e0d85"
      },
      "cell_type": "code",
      "source": [
        "celebanger = Image.open(\"celeb_fer1.jpg\")\n",
        "\n",
        "celebanger = celebanger.convert('L')\n",
        "celebanger = celebanger.resize((48,48))\n",
        "from IPython.display import display\n",
        "display(celebanger)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAHwUlEQVR4nAXBaYicZwEA4Pf+zvnm\nntkr083dZEtTY1tNWlAEWxWqKBQE9Z9gBY9Si0jRH/4qYlGhCkLRWpGq9aAqaSu1NGq3EXM0aWKa\nTbrJZmd3Z3Z2Zva7j/d7D58HHiaVLKOa27KglTS0bVE/FtR9CLPpYZUD2WCjfJMYTr80uihEJokk\n0YJxQVOKR2VFbDWcnVOfHtxe2Ds76d9vDQayWCCi935mhAkqtITz2NC4nha5MtTQssWBm516Hswm\nt0Lzzrsv5WVeHO+qfVs7fbZZK7P6BH7NvbgVTXRUb6m090jABt1/wcNbB+mzRoGMT443G7fH98/N\nJSBYsS615lZn4aT+8uN5eXrPqScs9ZWnosrNx/2ZqQ2d2/XpqLS1296wIvOBorX/QSJYd62FSp4w\nnLy4PHKIeeHsZO3zar8dXdo476q5BRkvgIhdbVZWzJfKmPfMsOcQOH0jqJgv/WBeADm8XvnNQxs9\nm4s+A2cfTLroylxQ3eO3g1tf/OUH07caNpnC1c3+pLLlUHNjYb6PTzzX+3AbnX9TvJwcJWyNho2i\nE0MfdQ8k4Xfn3/nEJoE/H1/OHcZrPtZWr/L6yU9RQabmO+dW/3NvUW5UkybH2Clw9+gfnr5vU8w3\n4QJImahEWZNNWOPI7JcJUDlNE3n59dUPTAYgSZpA53WcedVvzFlLVw4QwC3pxopEgMTA+EyIDRkj\nBHvI/vfqiVFpgMyQzXx0Ilt47clw0rqF0iwLx4nkCY/wwbsnOIMaQiQHZfPowguzUaIBhzHavxr7\ny+fnhiIgEgsildC4VICfZKpaCJJbILejRXc6pAJlytLmqFlEvZkLH4kXkVYSYYYpMGl9fj21FAcI\nJ4rkTdO6u2aIFFBqCivTw+Rpff26QEBjATXWsnTtJxfTUhoAMbft2JrajSO20KYSUjkQeCqp+bVt\nVEIoCs0RpbW7JqYui5yWsNCQKsSqugcyYIjNQYnkOAn+1hJjpITGMJV2fV/zPKxiUHck3wh2MqVF\nSazOUn1aWBXzpmmWQfnbU7XjSMOcUEYLEQT3vXDiJ1ujndGw0Qjx0CS7QbDiIANNmaQRwimbE++s\nIQZ0Xjhxoval3176ixgk4eaPvvPZX4ma6DbMnh43UCmR1tuhgzP+11spQoJgVFQ8ucx+/8zH4aAt\n+1n8xJcufB+vEcvJi5onvKBqU5W5RrkdHEQSKAiLXOT1tZ899Uh/RIvtdu/VP7Fv8i3qiIXRFNAx\n2kHab5bS3ov+CS2tUUlI4nZvfzW9YT73arFSfeXIRvAoq7Fdb/vFcSPmZiZptpcJ5nVa0JVYclOY\n5Oiez3H5sX4Czy7vtO3i799KllK5snK9o/pThxrcaRTV2DgOLU0EJ7au6d8V8I4g3Jjpz6wVoySf\nzO7v9vPlS1EzzwsMHFabeLPePIEKFxQJtlvsOuCipNObJ8N5hPMFzw8Clx+9arjG0uXAy2WtU8r3\nIVJmBmxYt1TJ2LVLb2Tt9tvtjrc4V08dw7NafZOS2eQQTVMEZSV2FEIcw4TCHM+GF5dv/Pmx1f6t\ndIotIxRl4e/sJHpvB3r2HYCqW8zQNIWWwBBBpxKbPw7cK+fg5gOtxmKBYay1L9T/oh3u4pmRv7HF\natprYkgAKUlhF8kRGQNj4dgVh0I3lkFRi7QgGRkUhpoc8o0pQZWyOXEJAQoBnXT1VLKlr9u9kwTh\n0IgFHlqptYtDZtqb9pkO0zUeIMA0RgBxQiphmx2r/PSO4bu/9hugqkldesriSQJ6iJKKOd42YxLx\nzM1ipAEFhaJeY79cdp//4eQUNyyNs2opFZq1KQAw3DSqK4WRV2sFnPEQVAJi2FTiCyp//s2VZx59\nReYIWtCBHPEMpHeGBlsfMMawqIGRzwmndmLCJk7Y5JnL92SXrlYjpA1Dq0opdiLvvbsQpgFIKxmv\n0mE3nyEmKNs5ltRNRhPymj93D5PaLJEpBeJsfIb9QodUlkyaFkdkUvMRliRhVpuPnT2n/3iNMOxI\nnggCILFBnM7XogJVFaSENUppm2hICqRRYfpBbsGHzx+c5UZGdmo0j1VoFsHujN8Mu1MIbOSJ1oRr\nbhAIS8Q2CcLjRbvNK0DFGc6UMMd6a3zDrgZTtI2Zivco7Q2pPWkSpW3GwNCjehpZ3InTIpRoyxIp\nviGyo3khgFIm6zoCDaAsiwSaJSV22FvzDjy8n5eE9sPt+aHBnR0xTZfgGT3giOh2k64XMG+oqQer\nOqqYDJTCfe4sMP3ML0GM4BTYE95V7x4YxJGR2C2XTznEmPECelZMOpstszCG3zu3Q10/h4bkHsyq\nvPePe7M3Sydvzt9cuEqZRbVF+/Cj52BEXcPFXhndNh9z3oJ2wA3tzPCiuSH9a0UDdhPct5SwGal7\nGzBbP0xcf+5QP7nrvTGwH+puuVMzgpWqM51JNt72pggaCcrrSTvwP8QNgPhibBRuUpKFdZ/J6JU5\nm3d8x8nHRRKe/q/SmSgiqjD1lNcYBckKUiWJKg1uz7ennFObHe90hsykjc64Uh7Xpu+4KE4Mh7tx\n7EiSInR+zMC1LXHaF/s6xwwvOm1VvFpjxkgZAmdNwnBoWDlDpo8oMlodC505vM7ddYe1rg7jC/e6\njWdpMAd2R8jsQDhCQogSo3apNBBA6ms3+P8BNjNoNnhNDhkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48 at 0x7FACA5BBC668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5AAzrfWFHGAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5450a033-4373-4e4e-ce27-c7df896f16d9"
      },
      "cell_type": "code",
      "source": [
        "celeb_img_np=np.asarray(celebanger)#.getdata()).reshape(48, 48, 1)\n",
        "celeb_img_np = celeb_img_np.reshape(48, 48, 1)\n",
        "print(celeb_img_np.shape)\n",
        "celeb_img_np = celeb_img_np / 255.0\n",
        "celeb_img_np = celeb_img_np - 0.5\n",
        "celeb_img_np = celeb_img_np * 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2LmFcuMmHfbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "501e112b-6432-4e48-e550-b9a94dd29362"
      },
      "cell_type": "code",
      "source": [
        "print(celeb_img_np.shape)\n",
        "y = model.predict(celeb_img_np)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 48, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-edcd21ba8eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceleb_img_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceleb_img_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1064\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking : expected image_array_input to have 4 dimensions, but got array with shape (48, 48, 1)"
          ]
        }
      ]
    }
  ]
}