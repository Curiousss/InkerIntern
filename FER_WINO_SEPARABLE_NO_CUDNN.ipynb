{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER_WINO_SEPARABLE_NO_CUDNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Curiousss/InkerIntern/blob/master/FER_WINO_SEPARABLE_NO_CUDNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Q9eNowMGaO_J",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "aaf543e4-1f59-43e3-e952-55e5b90d723e"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a75d4a7e-b69d-4001-98de-604e455b8133\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a75d4a7e-b69d-4001-98de-604e455b8133\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving baddata.txt to baddata.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BEb9SWJUV8T2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f9c4047-4e9d-4bd4-c5c2-e19676ad081f"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FWp55WPDUsSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9ade29b-c405-43be-d53e-e3ce92dc71ec"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "!export TF_ENABLE_WINOGRAD_NONFUSED=1\n",
        "os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'\n",
        "os.environ.pop('TF_ENABLE_WINOGRAD_NONFUSED', None)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "ldEdUzQbuQIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "dc356e96-16a4-4253-d356-0db4ee2a5581"
      },
      "cell_type": "code",
      "source": [
        "!tar xvf fer2013.tar\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fer2013/fer2013.csv\n",
            "fer2013/README\n",
            "fer2013/fer2013.bib\n",
            "fer2013/\n",
            "datalab  fer2013  fer2013.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dTyUIGDeuAQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b69f2c9-7e3d-41f3-956a-81e3b0380fba"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D, InputLayer\n",
        "from keras.layers import Convolution2D, SeparableConv2D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OqJCQeGxhq4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 48, 48\n",
        "batch_size = 128\n",
        "classes = 7\n",
        "epoch = 100\n",
        "img_channels = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sq7nNsVmhsYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "f = open('fer2013/fer2013.csv')\n",
        "csv_f = csv.reader(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQSDhHZ3tKqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "val_x =[]\n",
        "val_y =[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eWmuGFqNF5Ds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ToBeRemovedTrainingData = []\n",
        "with open(\"baddata.txt\", \"r\") as text:\n",
        "  for line in text:\n",
        "    ToBeRemovedTrainingData.append(int(line))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HmmgpkTpiWyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num=0\n",
        "for row in csv_f:\n",
        "  num = num +1\n",
        "  if num in ToBeRemovedTrainingData or num==1:\n",
        "    continue\n",
        "  #print(row)\n",
        "  #print(num)\n",
        "  temp_list = []\n",
        "  for pixel in row[1].split( ):\n",
        "    temp_list.append(int(pixel))\n",
        "\n",
        "  if str(row[2]) == \"Training\":\n",
        "    train_y.append(int(row[0]))\n",
        "    train_x.append(temp_list) \n",
        "  elif str(row[2]) == \"PublicTest\":\n",
        "    val_y.append(int(row[0]))\n",
        "    val_x.append(temp_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6rDJXl4rUKS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = np.asarray(train_x)\n",
        "train_y = np.asarray(train_y)\n",
        "val_x = np.asarray(val_x)\n",
        "val_y = np.asarray(val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lmXwV3InrVsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = train_x.reshape(train_x.shape[0], 48, 48)\n",
        "train_x = train_x.reshape(train_x.shape[0], 48, 48, 1 )\n",
        "train_y = np_utils.to_categorical(train_y, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3iZUfL1ztRu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_x = val_x.reshape(val_x.shape[0], 48, 48)\n",
        "val_x = val_x.reshape(val_x.shape[0], 48, 48, 1)\n",
        "val_y = np_utils.to_categorical(val_y, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FAWueVKKI0CR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "1b6319ae-6f2c-4231-e4ad-e95d28ae6433"
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "#print(train_x.shape)\n",
        "\n",
        "showimg = train_x[1].reshape(48,48)\n",
        "img = Image.fromarray(showimg.astype('uint8'))\n",
        "from IPython.display import display\n",
        "display(img)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAG60lEQVR4nAXB2Y+eZRUA8HPOc553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\nrkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48 at 0x7FACC3FCA1D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bkb-p1BXzBrI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = train_x.astype('float32')\n",
        "train_x = train_x / 255.0\n",
        "val_x = val_x.astype('float32')\n",
        "val_x = val_x / 255.0\n",
        "train_x = train_x - 0.5\n",
        "train_x = train_x * 2\n",
        "val_x = val_x - 0.5\n",
        "val_x = val_x * 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMKS1KOEGsB3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = (img_rows, img_cols, img_channels)\n",
        "model = Sequential()\n",
        "model.add(SeparableConv2D(filters=64, kernel_size=(3, 3), padding='same',\n",
        "                            name='image_array', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=512, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=512, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "#model.add(Flatten())\n",
        "'''\n",
        "model.add(Dense(1024))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(2048))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "'''\n",
        "model.add(InputLayer(input_shape=(3, 3, 1024)))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(7))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRsZspcA0uxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1454
        },
        "outputId": "468fc168-0b67-4fd0-8619-35326ded403f"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "image_array (SeparableConv2D (None, 48, 48, 64)        137       \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)   (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_22 (Separab (None, 48, 48, 64)        4736      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)   (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_23 (Separab (None, 24, 24, 128)       8896      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_24 (Separab (None, 24, 24, 128)       17664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_25 (Separab (None, 12, 12, 256)       34176     \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)   (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_26 (Separab (None, 12, 12, 256)       68096     \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)   (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_27 (Separab (None, 6, 6, 512)         133888    \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)   (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_28 (Separab (None, 6, 6, 512)         267264    \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)   (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "input_2 (InputLayer)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 7)                 3591      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 546,128\n",
            "Trainable params: 542,288\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hy0FyCcc2li0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "filepath='Model.best.hdf5'\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZYe0RPXn4O_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('Model.best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PB9jPqCQhXOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3710
        },
        "outputId": "c843bb9e-488b-4109-becc-44d29749db84"
      },
      "cell_type": "code",
      "source": [
        "# LReLU\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "model.fit(train_x, train_y, epochs=50, batch_size=batch_size, validation_data=(val_x, val_y), callbacks=[checkpointer])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28595 samples, validate on 3585 samples\n",
            "Epoch 1/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.7075 - acc: 0.7420 - val_loss: 0.9628 - val_acc: 0.6522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.65914\n",
            "Epoch 2/50\n",
            "25984/28595 [==========================>...] - ETA: 4s - loss: 0.6731 - acc: 0.7522"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.6755 - acc: 0.7515 - val_loss: 1.0152 - val_acc: 0.6569\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.65914\n",
            "Epoch 3/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.6598 - acc: 0.7600 - val_loss: 1.0179 - val_acc: 0.6452\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.65914\n",
            "Epoch 4/50\n",
            "10112/28595 [=========>....................] - ETA: 32s - loss: 0.6191 - acc: 0.7762"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.6424 - acc: 0.7626 - val_loss: 1.0279 - val_acc: 0.6491\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.65914\n",
            "Epoch 5/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.6282 - acc: 0.7692 - val_loss: 1.0259 - val_acc: 0.6575\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.65914\n",
            "Epoch 6/50\n",
            " 7296/28595 [======>.......................] - ETA: 37s - loss: 0.5956 - acc: 0.7797"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.6148 - acc: 0.7734 - val_loss: 0.9954 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.65914 to 0.66248, saving model to Model.best.hdf5\n",
            "Epoch 7/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.5981 - acc: 0.7794 - val_loss: 1.0378 - val_acc: 0.6622\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.66248\n",
            "Epoch 8/50\n",
            " 4096/28595 [===>..........................] - ETA: 43s - loss: 0.5680 - acc: 0.7920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.5905 - acc: 0.7822 - val_loss: 1.0229 - val_acc: 0.6594\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.66248\n",
            "Epoch 9/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.5770 - acc: 0.7890 - val_loss: 1.0805 - val_acc: 0.6522\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.66248\n",
            "Epoch 10/50\n",
            " 6144/28595 [=====>........................] - ETA: 39s - loss: 0.5427 - acc: 0.8037"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.5619 - acc: 0.7940 - val_loss: 1.0323 - val_acc: 0.6608\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.66248\n",
            "Epoch 11/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.5504 - acc: 0.7995 - val_loss: 1.0551 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.66248 to 0.66667, saving model to Model.best.hdf5\n",
            "Epoch 12/50\n",
            " 5888/28595 [=====>........................] - ETA: 39s - loss: 0.5097 - acc: 0.8196"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.5399 - acc: 0.8029 - val_loss: 1.1107 - val_acc: 0.6619\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.66667\n",
            "Epoch 13/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.5287 - acc: 0.8084 - val_loss: 1.0576 - val_acc: 0.6608\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.66667\n",
            "Epoch 14/50\n",
            " 6400/28595 [=====>........................] - ETA: 38s - loss: 0.4969 - acc: 0.8177"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.5234 - acc: 0.8063 - val_loss: 1.0448 - val_acc: 0.6692\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.66667 to 0.66918, saving model to Model.best.hdf5\n",
            "Epoch 15/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.5093 - acc: 0.8123 - val_loss: 1.0503 - val_acc: 0.6664\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.66918\n",
            "Epoch 16/50\n",
            " 3840/28595 [===>..........................] - ETA: 43s - loss: 0.4637 - acc: 0.8378"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.5009 - acc: 0.8178 - val_loss: 1.0700 - val_acc: 0.6630\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.66918\n",
            "Epoch 17/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4944 - acc: 0.8198 - val_loss: 1.0801 - val_acc: 0.6589\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.66918\n",
            "Epoch 18/50\n",
            " 6016/28595 [=====>........................] - ETA: 39s - loss: 0.4581 - acc: 0.8329"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4900 - acc: 0.8192 - val_loss: 1.0731 - val_acc: 0.6658\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.66918\n",
            "Epoch 19/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4669 - acc: 0.8294 - val_loss: 1.1012 - val_acc: 0.6636\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.66918\n",
            "Epoch 20/50\n",
            " 6400/28595 [=====>........................] - ETA: 38s - loss: 0.4461 - acc: 0.8386"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4717 - acc: 0.8266 - val_loss: 1.1356 - val_acc: 0.6580\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.66918\n",
            "Epoch 21/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4595 - acc: 0.8316 - val_loss: 1.1244 - val_acc: 0.6644\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.66918\n",
            "Epoch 22/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.4244 - acc: 0.8418"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4509 - acc: 0.8347 - val_loss: 1.1035 - val_acc: 0.6619\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.66918\n",
            "Epoch 23/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4543 - acc: 0.8342 - val_loss: 1.1276 - val_acc: 0.6608\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.66918\n",
            "Epoch 24/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.4119 - acc: 0.8516"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4434 - acc: 0.8387 - val_loss: 1.0854 - val_acc: 0.6700\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.66918 to 0.67001, saving model to Model.best.hdf5\n",
            "Epoch 25/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4358 - acc: 0.8386 - val_loss: 1.1194 - val_acc: 0.6639\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.67001\n",
            "Epoch 26/50\n",
            " 3840/28595 [===>..........................] - ETA: 43s - loss: 0.3982 - acc: 0.8526"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4275 - acc: 0.8437 - val_loss: 1.1517 - val_acc: 0.6689\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.67001\n",
            "Epoch 27/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4241 - acc: 0.8465 - val_loss: 1.1319 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.67001\n",
            "Epoch 28/50\n",
            " 6016/28595 [=====>........................] - ETA: 39s - loss: 0.4023 - acc: 0.8536"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4109 - acc: 0.8513 - val_loss: 1.1818 - val_acc: 0.6653\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.67001\n",
            "Epoch 29/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.4065 - acc: 0.8513 - val_loss: 1.1410 - val_acc: 0.6664\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.67001\n",
            "Epoch 30/50\n",
            " 6400/28595 [=====>........................] - ETA: 38s - loss: 0.3933 - acc: 0.8580"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3994 - acc: 0.8536 - val_loss: 1.1856 - val_acc: 0.6647\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.67001\n",
            "Epoch 31/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3979 - acc: 0.8558 - val_loss: 1.1573 - val_acc: 0.6644\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.67001\n",
            "Epoch 32/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.3648 - acc: 0.8644"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3896 - acc: 0.8569 - val_loss: 1.1412 - val_acc: 0.6639\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.67001\n",
            "Epoch 33/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3852 - acc: 0.8613 - val_loss: 1.1937 - val_acc: 0.6675\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.67001\n",
            "Epoch 34/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.3548 - acc: 0.8745"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3790 - acc: 0.8621 - val_loss: 1.1681 - val_acc: 0.6586\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.67001\n",
            "Epoch 35/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3752 - acc: 0.8609 - val_loss: 1.1846 - val_acc: 0.6636\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.67001\n",
            "Epoch 36/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.3538 - acc: 0.8727"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3729 - acc: 0.8644 - val_loss: 1.1917 - val_acc: 0.6603\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.67001\n",
            "Epoch 37/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3659 - acc: 0.8690 - val_loss: 1.1739 - val_acc: 0.6644\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.67001\n",
            "Epoch 38/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.3415 - acc: 0.8776"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3592 - acc: 0.8683 - val_loss: 1.1900 - val_acc: 0.6633\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.67001\n",
            "Epoch 39/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3584 - acc: 0.8696 - val_loss: 1.1743 - val_acc: 0.6642\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.67001\n",
            "Epoch 40/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.3214 - acc: 0.8860"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3466 - acc: 0.8753 - val_loss: 1.2020 - val_acc: 0.6608\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.67001\n",
            "Epoch 41/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3495 - acc: 0.8718 - val_loss: 1.2179 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.67001\n",
            "Epoch 42/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.3330 - acc: 0.8805"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3449 - acc: 0.8731 - val_loss: 1.2040 - val_acc: 0.6672\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.67001\n",
            "Epoch 43/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3419 - acc: 0.8756 - val_loss: 1.2115 - val_acc: 0.6630\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.67001\n",
            "Epoch 44/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.3187 - acc: 0.8822"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3379 - acc: 0.8781 - val_loss: 1.2434 - val_acc: 0.6572\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.67001\n",
            "Epoch 45/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3250 - acc: 0.8803 - val_loss: 1.2330 - val_acc: 0.6619\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.67001\n",
            "Epoch 46/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.3057 - acc: 0.8948"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3293 - acc: 0.8824 - val_loss: 1.2289 - val_acc: 0.6611\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.67001\n",
            "Epoch 47/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3289 - acc: 0.8809 - val_loss: 1.2550 - val_acc: 0.6561\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.67001\n",
            "Epoch 48/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.3079 - acc: 0.8854"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3208 - acc: 0.8838 - val_loss: 1.2594 - val_acc: 0.6583\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.67001\n",
            "Epoch 49/50\n",
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3176 - acc: 0.8845 - val_loss: 1.2558 - val_acc: 0.6669\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.67001\n",
            "Epoch 50/50\n",
            " 6528/28595 [=====>........................] - ETA: 38s - loss: 0.3054 - acc: 0.8902"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28595/28595 [==============================] - 52s 2ms/step - loss: 0.3208 - acc: 0.8827 - val_loss: 1.2596 - val_acc: 0.6616\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.67001\n",
            "--- 2601.835676431656 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rCSCjxwP6eMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "a5fad5cd-f021-43c1-d084-eb9fd7e0f8a6"
      },
      "cell_type": "code",
      "source": [
        "# input normalized\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "model.fit(train_x, train_y, epochs=10, batch_size=batch_size, validation_data=(val_x, val_y))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "Epoch 1/10\n",
            "28709/28709 [==============================] - 162s 6ms/step - loss: 2.0189 - acc: 0.2407 - val_loss: 1.8390 - val_acc: 0.2856\n",
            "Epoch 2/10\n",
            "28709/28709 [==============================] - 156s 5ms/step - loss: 1.8329 - acc: 0.2909 - val_loss: 1.7546 - val_acc: 0.3391\n",
            "Epoch 3/10\n",
            "  896/28709 [..............................] - ETA: 2:27 - loss: 1.7662 - acc: 0.3058"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28709/28709 [==============================] - 157s 5ms/step - loss: 1.7695 - acc: 0.3230 - val_loss: 1.8986 - val_acc: 0.3093\n",
            "Epoch 4/10\n",
            "28709/28709 [==============================] - 157s 5ms/step - loss: 1.7122 - acc: 0.3484 - val_loss: 1.6657 - val_acc: 0.3611\n",
            "Epoch 5/10\n",
            "10880/28709 [==========>...................] - ETA: 1:34 - loss: 1.6901 - acc: 0.3509"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28709/28709 [==============================] - 156s 5ms/step - loss: 1.6773 - acc: 0.3604 - val_loss: 1.7014 - val_acc: 0.3494\n",
            "Epoch 6/10\n",
            "28709/28709 [==============================] - 156s 5ms/step - loss: 1.6553 - acc: 0.3702 - val_loss: 1.6194 - val_acc: 0.3859\n",
            "Epoch 7/10\n",
            "13312/28709 [============>.................] - ETA: 1:20 - loss: 1.6141 - acc: 0.3857"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28709/28709 [==============================] - 156s 5ms/step - loss: 1.6129 - acc: 0.3857 - val_loss: 1.6001 - val_acc: 0.3923\n",
            "Epoch 8/10\n",
            "28709/28709 [==============================] - 156s 5ms/step - loss: 1.5920 - acc: 0.3924 - val_loss: 1.6594 - val_acc: 0.4035\n",
            "Epoch 9/10\n",
            "13824/28709 [=============>................] - ETA: 1:18 - loss: 1.5641 - acc: 0.4065"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28709/28709 [==============================] - 157s 5ms/step - loss: 1.5559 - acc: 0.4044 - val_loss: 1.5507 - val_acc: 0.4113\n",
            "Epoch 10/10\n",
            "28709/28709 [==============================] - 157s 5ms/step - loss: 1.5341 - acc: 0.4100 - val_loss: 1.5732 - val_acc: 0.4068\n",
            "--- 1574.3259291648865 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bJiUe6bEgjHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3692
        },
        "outputId": "ebe7fb11-9c47-4147-b2ca-d0d87ba6dcd6"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(train_x)\n",
        "\n",
        "model.fit_generator(datagen.flow(train_x, train_y,\n",
        "                    batch_size=batch_size),\n",
        "                    steps_per_epoch=(train_x.shape[0]/batch_size),\n",
        "                    epochs=50,\n",
        "                    validation_data=(val_x, val_y),\n",
        "                    callbacks=[checkpointer])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "224/223 [==============================] - 53s 236ms/step - loss: 0.9003 - acc: 0.6648 - val_loss: 1.0531 - val_acc: 0.6220\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.63961\n",
            "Epoch 2/50\n",
            "224/223 [==============================] - 53s 235ms/step - loss: 0.8919 - acc: 0.6664 - val_loss: 1.0446 - val_acc: 0.6310\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.63961\n",
            "Epoch 3/50\n",
            " 36/223 [===>..........................] - ETA: 42s - loss: 0.8790 - acc: 0.6808"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 53s 235ms/step - loss: 0.8823 - acc: 0.6721 - val_loss: 1.0371 - val_acc: 0.6234\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.63961\n",
            "Epoch 4/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8758 - acc: 0.6716 - val_loss: 1.0301 - val_acc: 0.6363\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.63961\n",
            "Epoch 5/50\n",
            " 54/223 [======>.......................] - ETA: 38s - loss: 0.8643 - acc: 0.6827"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8792 - acc: 0.6732 - val_loss: 1.0170 - val_acc: 0.6424\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.63961 to 0.64240, saving model to Model.best.hdf5\n",
            "Epoch 6/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8762 - acc: 0.6715 - val_loss: 1.0377 - val_acc: 0.6424\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.64240\n",
            "Epoch 7/50\n",
            " 36/223 [===>..........................] - ETA: 42s - loss: 0.8551 - acc: 0.6808"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8708 - acc: 0.6758 - val_loss: 1.0337 - val_acc: 0.6315\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.64240\n",
            "Epoch 8/50\n",
            "224/223 [==============================] - 53s 235ms/step - loss: 0.8677 - acc: 0.6773 - val_loss: 1.0320 - val_acc: 0.6418\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.64240\n",
            "Epoch 9/50\n",
            " 54/223 [======>.......................] - ETA: 38s - loss: 0.8408 - acc: 0.6875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8572 - acc: 0.6801 - val_loss: 1.0682 - val_acc: 0.6343\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.64240\n",
            "Epoch 10/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8519 - acc: 0.6828 - val_loss: 1.0535 - val_acc: 0.6388\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.64240\n",
            "Epoch 11/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.8346 - acc: 0.6846"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8492 - acc: 0.6834 - val_loss: 1.0351 - val_acc: 0.6471\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.64240 to 0.64714, saving model to Model.best.hdf5\n",
            "Epoch 12/50\n",
            "224/223 [==============================] - 53s 234ms/step - loss: 0.8476 - acc: 0.6843 - val_loss: 1.0267 - val_acc: 0.6393\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.64714\n",
            "Epoch 13/50\n",
            " 36/223 [===>..........................] - ETA: 42s - loss: 0.8419 - acc: 0.6886"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8474 - acc: 0.6843 - val_loss: 1.0526 - val_acc: 0.6424\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.64714\n",
            "Epoch 14/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8402 - acc: 0.6871 - val_loss: 1.0760 - val_acc: 0.6351\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.64714\n",
            "Epoch 15/50\n",
            " 53/223 [======>.......................] - ETA: 38s - loss: 0.8072 - acc: 0.7050"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 53s 234ms/step - loss: 0.8385 - acc: 0.6901 - val_loss: 1.0559 - val_acc: 0.6354\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.64714\n",
            "Epoch 16/50\n",
            "224/223 [==============================] - 53s 235ms/step - loss: 0.8340 - acc: 0.6895 - val_loss: 1.0230 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.64714\n",
            "Epoch 17/50\n",
            " 56/223 [======>.......................] - ETA: 37s - loss: 0.8082 - acc: 0.7070"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8255 - acc: 0.6928 - val_loss: 1.0323 - val_acc: 0.6416\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.64714\n",
            "Epoch 18/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8247 - acc: 0.6927 - val_loss: 1.0220 - val_acc: 0.6469\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.64714\n",
            "Epoch 19/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.8300 - acc: 0.6880"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 53s 235ms/step - loss: 0.8198 - acc: 0.6947 - val_loss: 1.0406 - val_acc: 0.6471\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.64714\n",
            "Epoch 20/50\n",
            "224/223 [==============================] - 53s 234ms/step - loss: 0.8226 - acc: 0.6941 - val_loss: 1.0299 - val_acc: 0.6360\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.64714\n",
            "Epoch 21/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.8278 - acc: 0.6939"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8220 - acc: 0.6958 - val_loss: 1.0348 - val_acc: 0.6416\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.64714\n",
            "Epoch 22/50\n",
            "224/223 [==============================] - 53s 235ms/step - loss: 0.8095 - acc: 0.6999 - val_loss: 1.0447 - val_acc: 0.6404\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.64714\n",
            "Epoch 23/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.8081 - acc: 0.6973"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8074 - acc: 0.6965 - val_loss: 1.0255 - val_acc: 0.6382\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.64714\n",
            "Epoch 24/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.8052 - acc: 0.6994 - val_loss: 1.0484 - val_acc: 0.6399\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.64714\n",
            "Epoch 25/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.8049 - acc: 0.7034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 53s 235ms/step - loss: 0.8066 - acc: 0.6995 - val_loss: 1.0101 - val_acc: 0.6497\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.64714 to 0.64965, saving model to Model.best.hdf5\n",
            "Epoch 26/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7903 - acc: 0.7075 - val_loss: 1.0390 - val_acc: 0.6499\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.64965 to 0.64993, saving model to Model.best.hdf5\n",
            "Epoch 27/50\n",
            " 33/223 [===>..........................] - ETA: 42s - loss: 0.7768 - acc: 0.7173"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7896 - acc: 0.7077 - val_loss: 1.0273 - val_acc: 0.6591\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.64993 to 0.65914, saving model to Model.best.hdf5\n",
            "Epoch 28/50\n",
            "224/223 [==============================] - 53s 235ms/step - loss: 0.7909 - acc: 0.7064 - val_loss: 1.0175 - val_acc: 0.6502\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.65914\n",
            "Epoch 29/50\n",
            " 32/223 [===>..........................] - ETA: 43s - loss: 0.7733 - acc: 0.7114"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7830 - acc: 0.7085 - val_loss: 1.0650 - val_acc: 0.6480\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.65914\n",
            "Epoch 30/50\n",
            "224/223 [==============================] - 53s 235ms/step - loss: 0.7802 - acc: 0.7102 - val_loss: 1.0082 - val_acc: 0.6502\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.65914\n",
            "Epoch 31/50\n",
            " 53/223 [======>.......................] - ETA: 38s - loss: 0.7744 - acc: 0.7121"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 53s 234ms/step - loss: 0.7830 - acc: 0.7080 - val_loss: 1.0201 - val_acc: 0.6502\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.65914\n",
            "Epoch 32/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7788 - acc: 0.7093 - val_loss: 1.0198 - val_acc: 0.6538\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.65914\n",
            "Epoch 33/50\n",
            " 56/223 [======>.......................] - ETA: 37s - loss: 0.7709 - acc: 0.7073"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 53s 235ms/step - loss: 0.7751 - acc: 0.7097 - val_loss: 1.0021 - val_acc: 0.6510\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.65914\n",
            "Epoch 34/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7724 - acc: 0.7137 - val_loss: 1.0401 - val_acc: 0.6513\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.65914\n",
            "Epoch 35/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.7511 - acc: 0.7164"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7677 - acc: 0.7125 - val_loss: 1.0227 - val_acc: 0.6491\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.65914\n",
            "Epoch 36/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7602 - acc: 0.7161 - val_loss: 1.0443 - val_acc: 0.6416\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.65914\n",
            "Epoch 37/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.7404 - acc: 0.7241"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7630 - acc: 0.7131 - val_loss: 1.0208 - val_acc: 0.6575\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.65914\n",
            "Epoch 38/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7549 - acc: 0.7216 - val_loss: 1.0358 - val_acc: 0.6547\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.65914\n",
            "Epoch 39/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.7474 - acc: 0.7281"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7617 - acc: 0.7196 - val_loss: 1.0656 - val_acc: 0.6449\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.65914\n",
            "Epoch 40/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7540 - acc: 0.7186 - val_loss: 1.0626 - val_acc: 0.6416\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.65914\n",
            "Epoch 41/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.7535 - acc: 0.7207"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7511 - acc: 0.7232 - val_loss: 1.0254 - val_acc: 0.6586\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.65914\n",
            "Epoch 42/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7489 - acc: 0.7211 - val_loss: 1.0770 - val_acc: 0.6393\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.65914\n",
            "Epoch 43/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.7315 - acc: 0.7245"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7469 - acc: 0.7237 - val_loss: 1.0719 - val_acc: 0.6402\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.65914\n",
            "Epoch 44/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7377 - acc: 0.7256 - val_loss: 1.0334 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.65914\n",
            "Epoch 45/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.7166 - acc: 0.7371"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7384 - acc: 0.7273 - val_loss: 1.0637 - val_acc: 0.6483\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.65914\n",
            "Epoch 46/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7306 - acc: 0.7310 - val_loss: 1.0610 - val_acc: 0.6385\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.65914\n",
            "Epoch 47/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.7169 - acc: 0.7311"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 52s 233ms/step - loss: 0.7304 - acc: 0.7276 - val_loss: 1.0796 - val_acc: 0.6391\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.65914\n",
            "Epoch 48/50\n",
            "224/223 [==============================] - 52s 234ms/step - loss: 0.7170 - acc: 0.7375 - val_loss: 1.0294 - val_acc: 0.6519\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.65914\n",
            "Epoch 49/50\n",
            " 57/223 [======>.......................] - ETA: 37s - loss: 0.7121 - acc: 0.7287"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "224/223 [==============================] - 53s 235ms/step - loss: 0.7289 - acc: 0.7249 - val_loss: 1.0328 - val_acc: 0.6586\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.65914\n",
            "Epoch 50/50\n",
            "224/223 [==============================] - 53s 235ms/step - loss: 0.7254 - acc: 0.7313 - val_loss: 1.0339 - val_acc: 0.6558\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.65914\n",
            "--- 2624.8869824409485 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}