{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER_WINO_SEPARABLE_NO_CUDNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Curiousss/InkerIntern/blob/master/FER_WINO_SEPARABLE_NO_CUDNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Q9eNowMGaO_J",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "a2de03f2-73fa-4a21-9905-dab09fffd980"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e7a50736-3fbf-4329-90ea-9e1df7e51517\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e7a50736-3fbf-4329-90ea-9e1df7e51517\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving baddata.txt to baddata.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BEb9SWJUV8T2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ea861d0-cdc0-4286-b93b-59361c0548e9"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  fer2013.tar\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ldEdUzQbuQIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "fa1f7c30-c8b0-4725-b742-3500ee1754bb"
      },
      "cell_type": "code",
      "source": [
        "!tar xvf fer2013.tar\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fer2013/fer2013.csv\n",
            "fer2013/README\n",
            "fer2013/fer2013.bib\n",
            "fer2013/\n",
            "datalab  fer2013  fer2013.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dTyUIGDeuAQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47252ee3-568e-47dd-f89d-36be332f387d"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D, InputLayer\n",
        "from keras.layers import Convolution2D, SeparableConv2D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OqJCQeGxhq4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 48, 48\n",
        "batch_size = 64\n",
        "classes = 7\n",
        "epoch = 100\n",
        "img_channels = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sq7nNsVmhsYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "f = open('fer2013/fer2013.csv')\n",
        "csv_f = csv.reader(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQSDhHZ3tKqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "val_x =[]\n",
        "val_y =[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eWmuGFqNF5Ds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ToBeRemovedTrainingData = []\n",
        "with open(\"baddata.txt\", \"r\") as text:\n",
        "  for line in text:\n",
        "    ToBeRemovedTrainingData.append(int(line))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HmmgpkTpiWyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num=0\n",
        "for row in csv_f:\n",
        "  num = num +1\n",
        "  if num in ToBeRemovedTrainingData or num==1:\n",
        "    continue\n",
        "  #print(row)\n",
        "  #print(num)\n",
        "  temp_list = []\n",
        "  for pixel in row[1].split( ):\n",
        "    temp_list.append(int(pixel))\n",
        "\n",
        "  if str(row[2]) == \"Training\":\n",
        "    train_y.append(int(row[0]))\n",
        "    train_x.append(temp_list) \n",
        "  elif str(row[2]) == \"PublicTest\":\n",
        "    val_y.append(int(row[0]))\n",
        "    val_x.append(temp_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6rDJXl4rUKS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = np.asarray(train_x)\n",
        "train_y = np.asarray(train_y)\n",
        "val_x = np.asarray(val_x)\n",
        "val_y = np.asarray(val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lmXwV3InrVsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = train_x.reshape(train_x.shape[0], 48, 48)\n",
        "train_x = train_x.reshape(train_x.shape[0], 48, 48, 1 )\n",
        "train_y = np_utils.to_categorical(train_y, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3iZUfL1ztRu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_x = val_x.reshape(val_x.shape[0], 48, 48)\n",
        "val_x = val_x.reshape(val_x.shape[0], 48, 48, 1)\n",
        "val_y = np_utils.to_categorical(val_y, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FAWueVKKI0CR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "691de95b-8fcc-4194-93a6-2b21d637e948"
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "#print(train_x.shape)\n",
        "\n",
        "showimg = train_x[1].reshape(48,48)\n",
        "img = Image.fromarray(showimg.astype('uint8'))\n",
        "from IPython.display import display\n",
        "display(img)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAHO0lEQVR4nAXB2Y4cVxkA4LP8Z6ut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\nFH15IbD7P4euDm5pw/eMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48 at 0x7F0AC359D400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bkb-p1BXzBrI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x = train_x.astype('float32')\n",
        "train_x = train_x / 255.0\n",
        "val_x = val_x.astype('float32')\n",
        "val_x = val_x / 255.0\n",
        "train_x = train_x - 0.5\n",
        "train_x = train_x * 2\n",
        "val_x = val_x - 0.5\n",
        "val_x = val_x * 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMKS1KOEGsB3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = (img_rows, img_cols, img_channels)\n",
        "model = Sequential()\n",
        "model.add(SeparableConv2D(filters=64, kernel_size=(3, 3), padding='same',\n",
        "                            name='image_array', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(.3))\n",
        "\n",
        "model.add(SeparableConv2D(filters=512, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=512, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(.3))\n",
        "'''\n",
        "model.add(SeparableConv2D(filters=1024, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(SeparableConv2D(filters=1024, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "'''\n",
        "#model.add(Flatten())\n",
        "'''\n",
        "model.add(Dense(1024))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(2048))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "'''\n",
        "model.add(InputLayer(input_shape=(3, 3, 1024)))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "'''\n",
        "model.add(Dense(2048))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(.5))\n",
        "'''\n",
        "model.add(Dense(7))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRsZspcA0uxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1454
        },
        "outputId": "6791d992-92ec-4353-d472-853ff3592c09"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "image_array (SeparableConv2D (None, 48, 48, 64)        153       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_1 (Separabl (None, 48, 48, 64)        5760      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_2 (Separabl (None, 24, 24, 128)       9920      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_3 (Separabl (None, 24, 24, 128)       19712     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_4 (Separabl (None, 12, 12, 256)       36224     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_5 (Separabl (None, 12, 12, 256)       72192     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_6 (Separabl (None, 6, 6, 512)         137984    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_7 (Separabl (None, 6, 6, 512)         275456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "input_1 (InputLayer)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 3591      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 568,672\n",
            "Trainable params: 564,832\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hy0FyCcc2li0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "filepath='Model.best.hdf5'\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZYe0RPXn4O_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('Model.best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJiUe6bEgjHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3692
        },
        "outputId": "de5b17b2-d43f-49cc-a8da-80185503caf9"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2)  # randomly flip images\n",
        "\n",
        "datagen.fit(train_x)\n",
        "\n",
        "model.fit_generator(datagen.flow(train_x, train_y,\n",
        "                    batch_size=batch_size),\n",
        "                    steps_per_epoch=(train_x.shape[0]/batch_size),\n",
        "                    epochs=50,\n",
        "                    validation_data=(val_x, val_y),\n",
        "                    callbacks=[checkpointer])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4846 - acc: 0.8248 - val_loss: 1.3189 - val_acc: 0.6254\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.65495\n",
            "Epoch 2/50\n",
            "214/446 [=============>................] - ETA: 29s - loss: 0.4844 - acc: 0.8243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4891 - acc: 0.8184 - val_loss: 1.2999 - val_acc: 0.6407\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.65495\n",
            "Epoch 3/50\n",
            "305/446 [===================>..........] - ETA: 17s - loss: 0.4690 - acc: 0.8299"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4735 - acc: 0.8283 - val_loss: 1.3115 - val_acc: 0.6357\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.65495\n",
            "Epoch 4/50\n",
            "333/446 [=====================>........] - ETA: 14s - loss: 0.4677 - acc: 0.8294"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4716 - acc: 0.8275 - val_loss: 1.2944 - val_acc: 0.6338\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.65495\n",
            "Epoch 5/50\n",
            "341/446 [=====================>........] - ETA: 13s - loss: 0.4774 - acc: 0.8262"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4774 - acc: 0.8253 - val_loss: 1.2248 - val_acc: 0.6466\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.65495\n",
            "Epoch 6/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4763 - acc: 0.8277"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4786 - acc: 0.8259 - val_loss: 1.2341 - val_acc: 0.6385\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.65495\n",
            "Epoch 7/50\n",
            "344/446 [======================>.......] - ETA: 12s - loss: 0.4693 - acc: 0.8306"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 130ms/step - loss: 0.4782 - acc: 0.8282 - val_loss: 1.2770 - val_acc: 0.6371\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.65495\n",
            "Epoch 8/50\n",
            "344/446 [======================>.......] - ETA: 12s - loss: 0.4760 - acc: 0.8291"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4796 - acc: 0.8267 - val_loss: 1.2626 - val_acc: 0.6499\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.65495\n",
            "Epoch 9/50\n",
            "344/446 [======================>.......] - ETA: 12s - loss: 0.4633 - acc: 0.8321"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4634 - acc: 0.8314 - val_loss: 1.2743 - val_acc: 0.6460\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.65495\n",
            "Epoch 10/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4576 - acc: 0.8335"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4624 - acc: 0.8320 - val_loss: 1.3041 - val_acc: 0.6374\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.65495\n",
            "Epoch 11/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4535 - acc: 0.8344"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 130ms/step - loss: 0.4570 - acc: 0.8329 - val_loss: 1.2532 - val_acc: 0.6483\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.65495\n",
            "Epoch 12/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4527 - acc: 0.8338"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4587 - acc: 0.8319 - val_loss: 1.2365 - val_acc: 0.6483\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.65495\n",
            "Epoch 13/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4541 - acc: 0.8344"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4565 - acc: 0.8336 - val_loss: 1.2697 - val_acc: 0.6430\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.65495\n",
            "Epoch 14/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4569 - acc: 0.8335"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4603 - acc: 0.8309 - val_loss: 1.2763 - val_acc: 0.6396\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.65495\n",
            "Epoch 15/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4483 - acc: 0.8359"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4489 - acc: 0.8363 - val_loss: 1.3051 - val_acc: 0.6335\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.65495\n",
            "Epoch 16/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4542 - acc: 0.8353"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4593 - acc: 0.8335 - val_loss: 1.3082 - val_acc: 0.6393\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.65495\n",
            "Epoch 17/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4429 - acc: 0.8385"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4503 - acc: 0.8360 - val_loss: 1.3121 - val_acc: 0.6371\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.65495\n",
            "Epoch 18/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4411 - acc: 0.8404"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4443 - acc: 0.8390 - val_loss: 1.3533 - val_acc: 0.6402\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.65495\n",
            "Epoch 19/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4408 - acc: 0.8386"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4460 - acc: 0.8358 - val_loss: 1.3410 - val_acc: 0.6318\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.65495\n",
            "Epoch 20/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4337 - acc: 0.8421"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4404 - acc: 0.8386 - val_loss: 1.3309 - val_acc: 0.6499\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.65495\n",
            "Epoch 21/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4421 - acc: 0.8371"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4414 - acc: 0.8375 - val_loss: 1.3835 - val_acc: 0.6315\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.65495\n",
            "Epoch 22/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4440 - acc: 0.8380"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4490 - acc: 0.8351 - val_loss: 1.3040 - val_acc: 0.6404\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.65495\n",
            "Epoch 23/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4256 - acc: 0.8444"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4306 - acc: 0.8419 - val_loss: 1.3044 - val_acc: 0.6494\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.65495\n",
            "Epoch 24/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4260 - acc: 0.8458"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4312 - acc: 0.8436 - val_loss: 1.3574 - val_acc: 0.6402\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.65495\n",
            "Epoch 25/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4272 - acc: 0.8424"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4314 - acc: 0.8417 - val_loss: 1.3438 - val_acc: 0.6438\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.65495\n",
            "Epoch 26/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4303 - acc: 0.8438"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4356 - acc: 0.8411 - val_loss: 1.2835 - val_acc: 0.6424\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.65495\n",
            "Epoch 27/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4205 - acc: 0.8467"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4286 - acc: 0.8437 - val_loss: 1.3434 - val_acc: 0.6396\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.65495\n",
            "Epoch 28/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4285 - acc: 0.8442"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4324 - acc: 0.8428 - val_loss: 1.3532 - val_acc: 0.6382\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.65495\n",
            "Epoch 29/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4287 - acc: 0.8411"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4276 - acc: 0.8423 - val_loss: 1.3061 - val_acc: 0.6410\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.65495\n",
            "Epoch 30/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4195 - acc: 0.8479"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4244 - acc: 0.8440 - val_loss: 1.3327 - val_acc: 0.6427\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.65495\n",
            "Epoch 31/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4174 - acc: 0.8493"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4253 - acc: 0.8459 - val_loss: 1.3659 - val_acc: 0.6377\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.65495\n",
            "Epoch 32/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4117 - acc: 0.8512"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4153 - acc: 0.8506 - val_loss: 1.3530 - val_acc: 0.6407\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.65495\n",
            "Epoch 33/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4092 - acc: 0.8520"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4145 - acc: 0.8492 - val_loss: 1.3644 - val_acc: 0.6497\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.65495\n",
            "Epoch 34/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4146 - acc: 0.8473"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 130ms/step - loss: 0.4196 - acc: 0.8458 - val_loss: 1.3119 - val_acc: 0.6404\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.65495\n",
            "Epoch 35/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4168 - acc: 0.8460"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4203 - acc: 0.8459 - val_loss: 1.3655 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.65495\n",
            "Epoch 36/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4107 - acc: 0.8502"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4141 - acc: 0.8483 - val_loss: 1.3224 - val_acc: 0.6421\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.65495\n",
            "Epoch 37/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4121 - acc: 0.8491"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4144 - acc: 0.8487 - val_loss: 1.3447 - val_acc: 0.6488\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.65495\n",
            "Epoch 38/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4019 - acc: 0.8540"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4093 - acc: 0.8518 - val_loss: 1.3193 - val_acc: 0.6491\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.65495\n",
            "Epoch 39/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4052 - acc: 0.8529"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4078 - acc: 0.8510 - val_loss: 1.3698 - val_acc: 0.6410\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.65495\n",
            "Epoch 40/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4029 - acc: 0.8530"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4066 - acc: 0.8514 - val_loss: 1.3503 - val_acc: 0.6424\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.65495\n",
            "Epoch 41/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.4054 - acc: 0.8536"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4087 - acc: 0.8524 - val_loss: 1.3521 - val_acc: 0.6519\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.65495\n",
            "Epoch 42/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.3965 - acc: 0.8551"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4033 - acc: 0.8528 - val_loss: 1.3606 - val_acc: 0.6340\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.65495\n",
            "Epoch 43/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.3967 - acc: 0.8550"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.3979 - acc: 0.8548 - val_loss: 1.3885 - val_acc: 0.6399\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.65495\n",
            "Epoch 44/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.3868 - acc: 0.8628"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.3923 - acc: 0.8610 - val_loss: 1.3939 - val_acc: 0.6505\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.65495\n",
            "Epoch 45/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.3964 - acc: 0.8560"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.4043 - acc: 0.8526 - val_loss: 1.3869 - val_acc: 0.6491\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.65495\n",
            "Epoch 46/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.3919 - acc: 0.8578"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.3940 - acc: 0.8567 - val_loss: 1.4165 - val_acc: 0.6388\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.65495\n",
            "Epoch 47/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.3956 - acc: 0.8570"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 58s 131ms/step - loss: 0.4002 - acc: 0.8554 - val_loss: 1.3328 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.65495\n",
            "Epoch 48/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.3958 - acc: 0.8566"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.3993 - acc: 0.8550 - val_loss: 1.4307 - val_acc: 0.6298\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.65495\n",
            "Epoch 49/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.3863 - acc: 0.8577"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 131ms/step - loss: 0.3930 - acc: 0.8559 - val_loss: 1.4264 - val_acc: 0.6519\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.65495\n",
            "Epoch 50/50\n",
            "343/446 [======================>.......] - ETA: 13s - loss: 0.3832 - acc: 0.8603"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447/446 [==============================] - 59s 132ms/step - loss: 0.3893 - acc: 0.8575 - val_loss: 1.3739 - val_acc: 0.6416\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.65495\n",
            "--- 2925.677119731903 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Zgb4ojyDNYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5209
        },
        "outputId": "47a7f747-79a3-4118-b86f-cb05be2142f4"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "start_time  = time.time()\n",
        "model.fit(train_x, train_y, epochs=150, batch_size=batch_size, validation_data=(val_x, val_y),\n",
        "             callbacks=[checkpointer])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28596 samples, validate on 3585 samples\n",
            "Epoch 1/150\n",
            "28596/28596 [==============================] - 54s 2ms/step - loss: 0.4168 - acc: 0.8481 - val_loss: 1.0697 - val_acc: 0.6728\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.66639 to 0.67280, saving model to Model.best.hdf5\n",
            "Epoch 2/150\n",
            "23168/28596 [=======================>......] - ETA: 9s - loss: 0.2719 - acc: 0.9060"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.2782 - acc: 0.9025 - val_loss: 1.1955 - val_acc: 0.6731\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.67280 to 0.67308, saving model to Model.best.hdf5\n",
            "Epoch 3/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.1861 - acc: 0.9368 - val_loss: 1.4794 - val_acc: 0.6628\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.67308\n",
            "Epoch 4/150\n",
            " 6656/28596 [=====>........................] - ETA: 39s - loss: 0.1150 - acc: 0.9668"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.1372 - acc: 0.9564 - val_loss: 1.5617 - val_acc: 0.6711\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.67308\n",
            "Epoch 5/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.1132 - acc: 0.9656 - val_loss: 1.6999 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.67308\n",
            "Epoch 6/150\n",
            " 6528/28596 [=====>........................] - ETA: 39s - loss: 0.0761 - acc: 0.9779"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0903 - acc: 0.9738 - val_loss: 1.8264 - val_acc: 0.6563\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.67308\n",
            "Epoch 7/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0854 - acc: 0.9750 - val_loss: 2.0439 - val_acc: 0.6474\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.67308\n",
            "Epoch 8/150\n",
            " 6528/28596 [=====>........................] - ETA: 39s - loss: 0.0705 - acc: 0.9775"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0759 - acc: 0.9787 - val_loss: 1.9572 - val_acc: 0.6577\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.67308\n",
            "Epoch 9/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0702 - acc: 0.9798 - val_loss: 2.0472 - val_acc: 0.6474\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.67308\n",
            "Epoch 10/150\n",
            " 6528/28596 [=====>........................] - ETA: 39s - loss: 0.0474 - acc: 0.9884"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0587 - acc: 0.9835 - val_loss: 2.0232 - val_acc: 0.6611\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.67308\n",
            "Epoch 11/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0614 - acc: 0.9825 - val_loss: 2.0499 - val_acc: 0.6608\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.67308\n",
            "Epoch 12/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0516 - acc: 0.9858"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0636 - acc: 0.9821 - val_loss: 2.0345 - val_acc: 0.6616\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.67308\n",
            "Epoch 13/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0634 - acc: 0.9815 - val_loss: 2.1152 - val_acc: 0.6633\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.67308\n",
            "Epoch 14/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0570 - acc: 0.9853"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0608 - acc: 0.9837 - val_loss: 2.0495 - val_acc: 0.6577\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.67308\n",
            "Epoch 15/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0617 - acc: 0.9820 - val_loss: 2.1966 - val_acc: 0.6483\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.67308\n",
            "Epoch 16/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0469 - acc: 0.9873"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0556 - acc: 0.9843 - val_loss: 2.1425 - val_acc: 0.6516\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.67308\n",
            "Epoch 17/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0570 - acc: 0.9842 - val_loss: 2.1138 - val_acc: 0.6577\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.67308\n",
            "Epoch 18/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0504 - acc: 0.9877"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0498 - acc: 0.9869 - val_loss: 2.1538 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.67308\n",
            "Epoch 19/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0425 - acc: 0.9891 - val_loss: 2.2359 - val_acc: 0.6497\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.67308\n",
            "Epoch 20/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0464 - acc: 0.9886"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0461 - acc: 0.9874 - val_loss: 2.2100 - val_acc: 0.6642\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.67308\n",
            "Epoch 21/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0518 - acc: 0.9860 - val_loss: 2.2088 - val_acc: 0.6555\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.67308\n",
            "Epoch 22/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0407 - acc: 0.9894"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0468 - acc: 0.9870 - val_loss: 2.1485 - val_acc: 0.6656\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.67308\n",
            "Epoch 23/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0450 - acc: 0.9867 - val_loss: 2.3231 - val_acc: 0.6594\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.67308\n",
            "Epoch 24/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0390 - acc: 0.9898"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0452 - acc: 0.9875 - val_loss: 2.2566 - val_acc: 0.6622\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.67308\n",
            "Epoch 25/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0509 - acc: 0.9854 - val_loss: 2.2745 - val_acc: 0.6597\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.67308\n",
            "Epoch 26/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0499 - acc: 0.9855"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0591 - acc: 0.9834 - val_loss: 2.2358 - val_acc: 0.6497\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.67308\n",
            "Epoch 27/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0492 - acc: 0.9846 - val_loss: 2.2307 - val_acc: 0.6589\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.67308\n",
            "Epoch 28/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0311 - acc: 0.9917"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0439 - acc: 0.9877 - val_loss: 2.2365 - val_acc: 0.6552\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.67308\n",
            "Epoch 29/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0338 - acc: 0.9905 - val_loss: 2.3622 - val_acc: 0.6563\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.67308\n",
            "Epoch 30/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0304 - acc: 0.9911"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0373 - acc: 0.9902 - val_loss: 2.2663 - val_acc: 0.6469\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.67308\n",
            "Epoch 31/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0398 - acc: 0.9891 - val_loss: 2.3745 - val_acc: 0.6552\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.67308\n",
            "Epoch 32/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0373 - acc: 0.9884"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0433 - acc: 0.9878 - val_loss: 2.2397 - val_acc: 0.6418\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.67308\n",
            "Epoch 33/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0389 - acc: 0.9884 - val_loss: 2.2562 - val_acc: 0.6572\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.67308\n",
            "Epoch 34/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0345 - acc: 0.9908"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0388 - acc: 0.9898 - val_loss: 2.3161 - val_acc: 0.6575\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.67308\n",
            "Epoch 35/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0429 - acc: 0.9881 - val_loss: 2.3346 - val_acc: 0.6513\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.67308\n",
            "Epoch 36/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0351 - acc: 0.9906"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0399 - acc: 0.9887 - val_loss: 2.3780 - val_acc: 0.6538\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.67308\n",
            "Epoch 37/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0353 - acc: 0.9902 - val_loss: 2.3294 - val_acc: 0.6516\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.67308\n",
            "Epoch 38/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0362 - acc: 0.9909"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0366 - acc: 0.9901 - val_loss: 2.4727 - val_acc: 0.6466\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.67308\n",
            "Epoch 39/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0371 - acc: 0.9887 - val_loss: 2.4055 - val_acc: 0.6494\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.67308\n",
            "Epoch 40/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0340 - acc: 0.9919"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0386 - acc: 0.9894 - val_loss: 2.3262 - val_acc: 0.6527\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.67308\n",
            "Epoch 41/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0373 - acc: 0.9896 - val_loss: 2.3591 - val_acc: 0.6413\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.67308\n",
            "Epoch 42/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0330 - acc: 0.9912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0361 - acc: 0.9899 - val_loss: 2.3904 - val_acc: 0.6455\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.67308\n",
            "Epoch 43/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0415 - acc: 0.9890 - val_loss: 2.3944 - val_acc: 0.6502\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.67308\n",
            "Epoch 44/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0315 - acc: 0.9905"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0352 - acc: 0.9898 - val_loss: 2.3387 - val_acc: 0.6586\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.67308\n",
            "Epoch 45/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0302 - acc: 0.9920 - val_loss: 2.3593 - val_acc: 0.6477\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.67308\n",
            "Epoch 46/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0242 - acc: 0.9948"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0289 - acc: 0.9931 - val_loss: 2.3881 - val_acc: 0.6572\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.67308\n",
            "Epoch 47/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0271 - acc: 0.9932 - val_loss: 2.3377 - val_acc: 0.6541\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.67308\n",
            "Epoch 48/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0220 - acc: 0.9942"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0290 - acc: 0.9923 - val_loss: 2.4017 - val_acc: 0.6524\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.67308\n",
            "Epoch 49/150\n",
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0318 - acc: 0.9916 - val_loss: 2.4893 - val_acc: 0.6446\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.67308\n",
            "Epoch 50/150\n",
            " 6400/28596 [=====>........................] - ETA: 39s - loss: 0.0294 - acc: 0.9923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "28596/28596 [==============================] - 53s 2ms/step - loss: 0.0317 - acc: 0.9912 - val_loss: 2.4533 - val_acc: 0.6335\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.67308\n",
            "Epoch 51/150\n",
            " 3072/28596 [==>...........................] - ETA: 45s - loss: 0.0339 - acc: 0.9906"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-583d4a636c8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model.fit(train_x, train_y, epochs=150, batch_size=batch_size, validation_data=(val_x, val_y),\n\u001b[0;32m----> 5\u001b[0;31m              callbacks=[checkpointer])\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "WMaPXKT8FSGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "a0d5cdf5-008e-4b13-cf13-11adae5e0d85"
      },
      "cell_type": "code",
      "source": [
        "def predict_emotion(model, pic):\n",
        "  pic = pic.convert('L')\n",
        "  pic = pic.resize((48,48))\n",
        "  \n",
        "  from IPython.display import display\n",
        "  display(pic)\n",
        "  pic_np=np.asarray(pic)#.getdata()).reshape(48, 48, 1)\n",
        "  pic_np = pic_np.reshape(1, 48, 48, 1)\n",
        "  print(pic_np.shape)\n",
        "  pic_np = pic_np / 255.0\n",
        "  pic_np = pic_np - 0.5\n",
        "  pic_np = pic_np * 2\n",
        "  \n",
        "  print(pic_np.shape)\n",
        "  y = model.predict(pic_np)\n",
        "  print(\"0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\")\n",
        "  print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAHwUlEQVR4nAXBaYicZwEA4Pf+zvnm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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48 at 0x7FACA5BBC668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5AAzrfWFHGAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5450a033-4373-4e4e-ce27-c7df896f16d9"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2LmFcuMmHfbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "501e112b-6432-4e48-e550-b9a94dd29362"
      },
      "cell_type": "code",
      "source": [
        "celebanger = Image.open(\"celeb_fer1.jpg\")\n",
        "predict_emotion(model, celebanger)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 48, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-edcd21ba8eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceleb_img_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceleb_img_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1064\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking : expected image_array_input to have 4 dimensions, but got array with shape (48, 48, 1)"
          ]
        }
      ]
    }
  ]
}