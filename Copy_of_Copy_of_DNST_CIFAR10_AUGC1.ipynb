{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy_of_DNST_CIFAR10_AUGC1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Curiousss/InkerIntern/blob/master/Copy_of_Copy_of_DNST_CIFAR10_AUGC1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcc54f39-202b-4749-be34-4fd37fd0f37c"
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 20\n",
        "num_filter = 25\n",
        "compression = 0.8\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qNTU3O3cuF6Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator #, array_to_img, img_to_array, load_img\n",
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "'''        vertical_flip=True,\n",
        "        rotation_range=40,\n",
        "        horizontal_flip=True\n",
        "     fill_mode='nearest',\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "'''\n",
        "datagen.fit(x_train)\n",
        "train_gen = datagen.flow(x_train, y_train, batch_size)\n",
        "test_gen = datagen.flow(x_test, y_test, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#num_filter = 12\n",
        "#dropout_rate = 0.2\n",
        "#l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15844
        },
        "outputId": "19cc3454-224e-4669-b2fc-782e7369a088"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 32, 32, 25)   675         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 32, 32, 25)   100         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 32, 32, 25)   0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 32, 32, 20)   4500        activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 32, 32, 20)   0           conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 32, 32, 45)   0           conv2d_129[0][0]                 \n",
            "                                                                 dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 32, 32, 45)   180         concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 32, 32, 45)   0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 32, 32, 20)   8100        activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 32, 32, 20)   0           conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 32, 32, 65)   0           concatenate_121[0][0]            \n",
            "                                                                 dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 32, 32, 65)   260         concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 32, 32, 65)   0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 32, 32, 20)   11700       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 32, 32, 20)   0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 32, 32, 85)   0           concatenate_122[0][0]            \n",
            "                                                                 dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 32, 32, 85)   340         concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 32, 32, 85)   0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 32, 32, 20)   15300       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 32, 32, 20)   0           conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 32, 32, 105)  0           concatenate_123[0][0]            \n",
            "                                                                 dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 32, 32, 105)  420         concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 32, 32, 105)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 32, 32, 20)   18900       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 32, 32, 20)   0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 32, 32, 125)  0           concatenate_124[0][0]            \n",
            "                                                                 dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 32, 32, 125)  500         concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 32, 32, 125)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 32, 32, 20)   22500       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 32, 32, 20)   0           conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 32, 32, 145)  0           concatenate_125[0][0]            \n",
            "                                                                 dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 32, 32, 145)  580         concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 32, 32, 145)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 32, 32, 20)   26100       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 32, 32, 20)   0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 32, 32, 165)  0           concatenate_126[0][0]            \n",
            "                                                                 dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 32, 32, 165)  660         concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 32, 32, 165)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 32, 32, 20)   29700       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 32, 32, 20)   0           conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 32, 32, 185)  0           concatenate_127[0][0]            \n",
            "                                                                 dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 32, 32, 185)  740         concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 32, 32, 185)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 32, 32, 20)   33300       activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 32, 32, 20)   0           conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 32, 32, 205)  0           concatenate_128[0][0]            \n",
            "                                                                 dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 32, 32, 205)  820         concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 32, 32, 205)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 32, 32, 20)   36900       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 32, 32, 20)   0           conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 32, 32, 225)  0           concatenate_129[0][0]            \n",
            "                                                                 dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 32, 32, 225)  900         concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 32, 32, 225)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 32, 32, 20)   40500       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 32, 32, 20)   0           conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 32, 32, 245)  0           concatenate_130[0][0]            \n",
            "                                                                 dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 32, 32, 245)  980         concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 32, 32, 245)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 32, 32, 20)   44100       activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 32, 32, 20)   0           conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 32, 32, 265)  0           concatenate_131[0][0]            \n",
            "                                                                 dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 32, 32, 265)  1060        concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 32, 32, 265)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 32, 32, 20)   47700       activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 32, 32, 20)   0           conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_133 (Concatenate)   (None, 32, 32, 285)  0           concatenate_132[0][0]            \n",
            "                                                                 dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 32, 32, 285)  1140        concatenate_133[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 32, 32, 285)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 32, 32, 20)   51300       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 32, 32, 20)   0           conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_134 (Concatenate)   (None, 32, 32, 305)  0           concatenate_133[0][0]            \n",
            "                                                                 dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 32, 32, 305)  1220        concatenate_134[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 32, 32, 305)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 32, 32, 20)   54900       activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 32, 32, 20)   0           conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_135 (Concatenate)   (None, 32, 32, 325)  0           concatenate_134[0][0]            \n",
            "                                                                 dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 32, 32, 325)  1300        concatenate_135[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 32, 32, 325)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 32, 32, 20)   58500       activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 32, 32, 20)   0           conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_136 (Concatenate)   (None, 32, 32, 345)  0           concatenate_135[0][0]            \n",
            "                                                                 dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 32, 32, 345)  1380        concatenate_136[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 32, 32, 345)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 32, 32, 20)   62100       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_143 (Dropout)           (None, 32, 32, 20)   0           conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_137 (Concatenate)   (None, 32, 32, 365)  0           concatenate_136[0][0]            \n",
            "                                                                 dropout_143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 32, 32, 365)  1460        concatenate_137[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 32, 32, 365)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 32, 32, 20)   65700       activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 32, 32, 20)   0           conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_138 (Concatenate)   (None, 32, 32, 385)  0           concatenate_137[0][0]            \n",
            "                                                                 dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 32, 32, 385)  1540        concatenate_138[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 32, 32, 385)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 32, 32, 20)   69300       activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_145 (Dropout)           (None, 32, 32, 20)   0           conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_139 (Concatenate)   (None, 32, 32, 405)  0           concatenate_138[0][0]            \n",
            "                                                                 dropout_145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 32, 32, 405)  1620        concatenate_139[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 32, 32, 405)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 32, 32, 20)   72900       activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_146 (Dropout)           (None, 32, 32, 20)   0           conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_140 (Concatenate)   (None, 32, 32, 425)  0           concatenate_139[0][0]            \n",
            "                                                                 dropout_146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 32, 32, 425)  1700        concatenate_140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 32, 32, 425)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 32, 32, 20)   8500        activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_147 (Dropout)           (None, 32, 32, 20)   0           conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 20)   0           dropout_147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 16, 16, 20)   80          average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 16, 16, 20)   0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 16, 16, 20)   3600        activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_148 (Dropout)           (None, 16, 16, 20)   0           conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_141 (Concatenate)   (None, 16, 16, 40)   0           average_pooling2d_9[0][0]        \n",
            "                                                                 dropout_148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 16, 16, 40)   160         concatenate_141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 16, 16, 40)   0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 16, 16, 20)   7200        activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_149 (Dropout)           (None, 16, 16, 20)   0           conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_142 (Concatenate)   (None, 16, 16, 60)   0           concatenate_141[0][0]            \n",
            "                                                                 dropout_149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 16, 16, 60)   240         concatenate_142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 16, 16, 60)   0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 16, 16, 20)   10800       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_150 (Dropout)           (None, 16, 16, 20)   0           conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_143 (Concatenate)   (None, 16, 16, 80)   0           concatenate_142[0][0]            \n",
            "                                                                 dropout_150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 16, 16, 80)   320         concatenate_143[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 16, 16, 80)   0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 16, 16, 20)   14400       activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_151 (Dropout)           (None, 16, 16, 20)   0           conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_144 (Concatenate)   (None, 16, 16, 100)  0           concatenate_143[0][0]            \n",
            "                                                                 dropout_151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 16, 16, 100)  400         concatenate_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 16, 16, 100)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 16, 16, 20)   18000       activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_152 (Dropout)           (None, 16, 16, 20)   0           conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_145 (Concatenate)   (None, 16, 16, 120)  0           concatenate_144[0][0]            \n",
            "                                                                 dropout_152[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 16, 16, 120)  480         concatenate_145[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 16, 16, 120)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 16, 16, 20)   21600       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_153 (Dropout)           (None, 16, 16, 20)   0           conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_146 (Concatenate)   (None, 16, 16, 140)  0           concatenate_145[0][0]            \n",
            "                                                                 dropout_153[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 16, 16, 140)  560         concatenate_146[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 16, 16, 140)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 16, 16, 20)   25200       activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_154 (Dropout)           (None, 16, 16, 20)   0           conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_147 (Concatenate)   (None, 16, 16, 160)  0           concatenate_146[0][0]            \n",
            "                                                                 dropout_154[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 16, 16, 160)  640         concatenate_147[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 16, 16, 160)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 16, 16, 20)   28800       activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_155 (Dropout)           (None, 16, 16, 20)   0           conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_148 (Concatenate)   (None, 16, 16, 180)  0           concatenate_147[0][0]            \n",
            "                                                                 dropout_155[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 16, 16, 180)  720         concatenate_148[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 16, 16, 180)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 16, 16, 20)   32400       activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_156 (Dropout)           (None, 16, 16, 20)   0           conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_149 (Concatenate)   (None, 16, 16, 200)  0           concatenate_148[0][0]            \n",
            "                                                                 dropout_156[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 16, 16, 200)  800         concatenate_149[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 16, 16, 200)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 16, 16, 20)   36000       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_157 (Dropout)           (None, 16, 16, 20)   0           conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_150 (Concatenate)   (None, 16, 16, 220)  0           concatenate_149[0][0]            \n",
            "                                                                 dropout_157[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 16, 16, 220)  880         concatenate_150[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 16, 16, 220)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 16, 16, 20)   39600       activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_158 (Dropout)           (None, 16, 16, 20)   0           conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_151 (Concatenate)   (None, 16, 16, 240)  0           concatenate_150[0][0]            \n",
            "                                                                 dropout_158[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 16, 16, 240)  960         concatenate_151[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 16, 16, 240)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 16, 16, 20)   43200       activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_159 (Dropout)           (None, 16, 16, 20)   0           conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_152 (Concatenate)   (None, 16, 16, 260)  0           concatenate_151[0][0]            \n",
            "                                                                 dropout_159[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 16, 16, 260)  1040        concatenate_152[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 16, 16, 260)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 16, 16, 20)   46800       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_160 (Dropout)           (None, 16, 16, 20)   0           conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_153 (Concatenate)   (None, 16, 16, 280)  0           concatenate_152[0][0]            \n",
            "                                                                 dropout_160[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 16, 16, 280)  1120        concatenate_153[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 16, 16, 280)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 16, 16, 20)   50400       activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_161 (Dropout)           (None, 16, 16, 20)   0           conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_154 (Concatenate)   (None, 16, 16, 300)  0           concatenate_153[0][0]            \n",
            "                                                                 dropout_161[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 16, 16, 300)  1200        concatenate_154[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 16, 16, 300)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 16, 16, 20)   54000       activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_162 (Dropout)           (None, 16, 16, 20)   0           conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_155 (Concatenate)   (None, 16, 16, 320)  0           concatenate_154[0][0]            \n",
            "                                                                 dropout_162[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 16, 16, 320)  1280        concatenate_155[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 16, 16, 320)  0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 16, 16, 20)   57600       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_163 (Dropout)           (None, 16, 16, 20)   0           conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_156 (Concatenate)   (None, 16, 16, 340)  0           concatenate_155[0][0]            \n",
            "                                                                 dropout_163[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 16, 16, 340)  1360        concatenate_156[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 16, 16, 340)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 16, 16, 20)   61200       activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_164 (Dropout)           (None, 16, 16, 20)   0           conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_157 (Concatenate)   (None, 16, 16, 360)  0           concatenate_156[0][0]            \n",
            "                                                                 dropout_164[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 16, 16, 360)  1440        concatenate_157[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 16, 16, 360)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 16, 16, 20)   64800       activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_165 (Dropout)           (None, 16, 16, 20)   0           conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_158 (Concatenate)   (None, 16, 16, 380)  0           concatenate_157[0][0]            \n",
            "                                                                 dropout_165[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 16, 16, 380)  1520        concatenate_158[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 16, 16, 380)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 16, 16, 20)   68400       activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_166 (Dropout)           (None, 16, 16, 20)   0           conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_159 (Concatenate)   (None, 16, 16, 400)  0           concatenate_158[0][0]            \n",
            "                                                                 dropout_166[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 16, 16, 400)  1600        concatenate_159[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 16, 16, 400)  0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 16, 16, 20)   72000       activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_167 (Dropout)           (None, 16, 16, 20)   0           conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_160 (Concatenate)   (None, 16, 16, 420)  0           concatenate_159[0][0]            \n",
            "                                                                 dropout_167[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 16, 16, 420)  1680        concatenate_160[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 16, 16, 420)  0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 16, 16, 20)   8400        activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_168 (Dropout)           (None, 16, 16, 20)   0           conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 8, 8, 20)     0           dropout_168[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 20)     80          average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 8, 8, 20)     0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 20)     3600        activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_169 (Dropout)           (None, 8, 8, 20)     0           conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_161 (Concatenate)   (None, 8, 8, 40)     0           average_pooling2d_10[0][0]       \n",
            "                                                                 dropout_169[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 8, 8, 40)     160         concatenate_161[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 8, 8, 40)     0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 20)     7200        activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_170 (Dropout)           (None, 8, 8, 20)     0           conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_162 (Concatenate)   (None, 8, 8, 60)     0           concatenate_161[0][0]            \n",
            "                                                                 dropout_170[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 8, 8, 60)     240         concatenate_162[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 8, 8, 60)     0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 20)     10800       activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_171 (Dropout)           (None, 8, 8, 20)     0           conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_163 (Concatenate)   (None, 8, 8, 80)     0           concatenate_162[0][0]            \n",
            "                                                                 dropout_171[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 8, 8, 80)     320         concatenate_163[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 8, 8, 80)     0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 20)     14400       activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_172 (Dropout)           (None, 8, 8, 20)     0           conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_164 (Concatenate)   (None, 8, 8, 100)    0           concatenate_163[0][0]            \n",
            "                                                                 dropout_172[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 8, 8, 100)    400         concatenate_164[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 8, 8, 100)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 20)     18000       activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_173 (Dropout)           (None, 8, 8, 20)     0           conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_165 (Concatenate)   (None, 8, 8, 120)    0           concatenate_164[0][0]            \n",
            "                                                                 dropout_173[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 120)    480         concatenate_165[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 8, 8, 120)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 20)     21600       activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_174 (Dropout)           (None, 8, 8, 20)     0           conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_166 (Concatenate)   (None, 8, 8, 140)    0           concatenate_165[0][0]            \n",
            "                                                                 dropout_174[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 8, 8, 140)    560         concatenate_166[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 8, 8, 140)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 20)     25200       activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_175 (Dropout)           (None, 8, 8, 20)     0           conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_167 (Concatenate)   (None, 8, 8, 160)    0           concatenate_166[0][0]            \n",
            "                                                                 dropout_175[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 160)    640         concatenate_167[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 8, 8, 160)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 20)     28800       activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_176 (Dropout)           (None, 8, 8, 20)     0           conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_168 (Concatenate)   (None, 8, 8, 180)    0           concatenate_167[0][0]            \n",
            "                                                                 dropout_176[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 8, 8, 180)    720         concatenate_168[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 8, 8, 180)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 8, 8, 20)     32400       activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_177 (Dropout)           (None, 8, 8, 20)     0           conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_169 (Concatenate)   (None, 8, 8, 200)    0           concatenate_168[0][0]            \n",
            "                                                                 dropout_177[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 200)    800         concatenate_169[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 8, 8, 200)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 8, 8, 20)     36000       activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_178 (Dropout)           (None, 8, 8, 20)     0           conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_170 (Concatenate)   (None, 8, 8, 220)    0           concatenate_169[0][0]            \n",
            "                                                                 dropout_178[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 8, 8, 220)    880         concatenate_170[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 8, 8, 220)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 8, 8, 20)     39600       activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_179 (Dropout)           (None, 8, 8, 20)     0           conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_171 (Concatenate)   (None, 8, 8, 240)    0           concatenate_170[0][0]            \n",
            "                                                                 dropout_179[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 240)    960         concatenate_171[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 240)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 8, 8, 20)     43200       activation_182[0][0]             \n",
            "__________________________________________________________________________________________________"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dropout_180 (Dropout)           (None, 8, 8, 20)     0           conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_172 (Concatenate)   (None, 8, 8, 260)    0           concatenate_171[0][0]            \n",
            "                                                                 dropout_180[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 8, 8, 260)    1040        concatenate_172[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 8, 8, 260)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 8, 8, 20)     46800       activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_181 (Dropout)           (None, 8, 8, 20)     0           conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_173 (Concatenate)   (None, 8, 8, 280)    0           concatenate_172[0][0]            \n",
            "                                                                 dropout_181[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 280)    1120        concatenate_173[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 280)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 8, 8, 20)     50400       activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_182 (Dropout)           (None, 8, 8, 20)     0           conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_174 (Concatenate)   (None, 8, 8, 300)    0           concatenate_173[0][0]            \n",
            "                                                                 dropout_182[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 8, 8, 300)    1200        concatenate_174[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 300)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 8, 8, 20)     54000       activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_183 (Dropout)           (None, 8, 8, 20)     0           conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_175 (Concatenate)   (None, 8, 8, 320)    0           concatenate_174[0][0]            \n",
            "                                                                 dropout_183[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 8, 8, 320)    1280        concatenate_175[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 320)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 8, 8, 20)     57600       activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_184 (Dropout)           (None, 8, 8, 20)     0           conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_176 (Concatenate)   (None, 8, 8, 340)    0           concatenate_175[0][0]            \n",
            "                                                                 dropout_184[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 8, 8, 340)    1360        concatenate_176[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 8, 340)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 8, 8, 20)     61200       activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_185 (Dropout)           (None, 8, 8, 20)     0           conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_177 (Concatenate)   (None, 8, 8, 360)    0           concatenate_176[0][0]            \n",
            "                                                                 dropout_185[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 8, 8, 360)    1440        concatenate_177[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 8, 8, 360)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 8, 8, 20)     64800       activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_186 (Dropout)           (None, 8, 8, 20)     0           conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_178 (Concatenate)   (None, 8, 8, 380)    0           concatenate_177[0][0]            \n",
            "                                                                 dropout_186[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 8, 8, 380)    1520        concatenate_178[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 8, 8, 380)    0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 8, 8, 20)     68400       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_187 (Dropout)           (None, 8, 8, 20)     0           conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_179 (Concatenate)   (None, 8, 8, 400)    0           concatenate_178[0][0]            \n",
            "                                                                 dropout_187[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 8, 8, 400)    1600        concatenate_179[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 8, 8, 400)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 8, 8, 20)     72000       activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_188 (Dropout)           (None, 8, 8, 20)     0           conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_180 (Concatenate)   (None, 8, 8, 420)    0           concatenate_179[0][0]            \n",
            "                                                                 dropout_188[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 8, 8, 420)    1680        concatenate_180[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 8, 8, 420)    0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 8, 8, 20)     8400        activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_189 (Dropout)           (None, 8, 8, 20)     0           conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 4, 4, 20)     0           dropout_189[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 4, 4, 20)     80          average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 4, 4, 20)     0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 4, 4, 20)     3600        activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_190 (Dropout)           (None, 4, 4, 20)     0           conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_181 (Concatenate)   (None, 4, 4, 40)     0           average_pooling2d_11[0][0]       \n",
            "                                                                 dropout_190[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 4, 4, 40)     160         concatenate_181[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 4, 4, 40)     0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 4, 4, 20)     7200        activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_191 (Dropout)           (None, 4, 4, 20)     0           conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_182 (Concatenate)   (None, 4, 4, 60)     0           concatenate_181[0][0]            \n",
            "                                                                 dropout_191[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 4, 4, 60)     240         concatenate_182[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 4, 4, 60)     0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 4, 4, 20)     10800       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_192 (Dropout)           (None, 4, 4, 20)     0           conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_183 (Concatenate)   (None, 4, 4, 80)     0           concatenate_182[0][0]            \n",
            "                                                                 dropout_192[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 4, 4, 80)     320         concatenate_183[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 4, 4, 80)     0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 4, 4, 20)     14400       activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_193 (Dropout)           (None, 4, 4, 20)     0           conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_184 (Concatenate)   (None, 4, 4, 100)    0           concatenate_183[0][0]            \n",
            "                                                                 dropout_193[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 4, 4, 100)    400         concatenate_184[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 4, 4, 100)    0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 4, 4, 20)     18000       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_194 (Dropout)           (None, 4, 4, 20)     0           conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_185 (Concatenate)   (None, 4, 4, 120)    0           concatenate_184[0][0]            \n",
            "                                                                 dropout_194[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 4, 4, 120)    480         concatenate_185[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 4, 4, 120)    0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 4, 4, 20)     21600       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_195 (Dropout)           (None, 4, 4, 20)     0           conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_186 (Concatenate)   (None, 4, 4, 140)    0           concatenate_185[0][0]            \n",
            "                                                                 dropout_195[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 4, 4, 140)    560         concatenate_186[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 4, 4, 140)    0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 4, 4, 20)     25200       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_196 (Dropout)           (None, 4, 4, 20)     0           conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_187 (Concatenate)   (None, 4, 4, 160)    0           concatenate_186[0][0]            \n",
            "                                                                 dropout_196[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 4, 4, 160)    640         concatenate_187[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 4, 4, 160)    0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 4, 4, 20)     28800       activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_197 (Dropout)           (None, 4, 4, 20)     0           conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_188 (Concatenate)   (None, 4, 4, 180)    0           concatenate_187[0][0]            \n",
            "                                                                 dropout_197[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 4, 4, 180)    720         concatenate_188[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 4, 4, 180)    0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 4, 4, 20)     32400       activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_198 (Dropout)           (None, 4, 4, 20)     0           conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_189 (Concatenate)   (None, 4, 4, 200)    0           concatenate_188[0][0]            \n",
            "                                                                 dropout_198[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 4, 4, 200)    800         concatenate_189[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 4, 4, 200)    0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 4, 4, 20)     36000       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_199 (Dropout)           (None, 4, 4, 20)     0           conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_190 (Concatenate)   (None, 4, 4, 220)    0           concatenate_189[0][0]            \n",
            "                                                                 dropout_199[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 4, 4, 220)    880         concatenate_190[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 4, 4, 220)    0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 4, 4, 20)     39600       activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_200 (Dropout)           (None, 4, 4, 20)     0           conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_191 (Concatenate)   (None, 4, 4, 240)    0           concatenate_190[0][0]            \n",
            "                                                                 dropout_200[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 4, 4, 240)    960         concatenate_191[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 4, 4, 240)    0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 4, 4, 20)     43200       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_201 (Dropout)           (None, 4, 4, 20)     0           conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_192 (Concatenate)   (None, 4, 4, 260)    0           concatenate_191[0][0]            \n",
            "                                                                 dropout_201[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 4, 4, 260)    1040        concatenate_192[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 4, 4, 260)    0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 4, 4, 20)     46800       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_202 (Dropout)           (None, 4, 4, 20)     0           conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_193 (Concatenate)   (None, 4, 4, 280)    0           concatenate_192[0][0]            \n",
            "                                                                 dropout_202[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 4, 4, 280)    1120        concatenate_193[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 4, 4, 280)    0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 4, 4, 20)     50400       activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_203 (Dropout)           (None, 4, 4, 20)     0           conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_194 (Concatenate)   (None, 4, 4, 300)    0           concatenate_193[0][0]            \n",
            "                                                                 dropout_203[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 4, 4, 300)    1200        concatenate_194[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 4, 4, 300)    0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 4, 4, 20)     54000       activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_204 (Dropout)           (None, 4, 4, 20)     0           conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_195 (Concatenate)   (None, 4, 4, 320)    0           concatenate_194[0][0]            \n",
            "                                                                 dropout_204[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 4, 4, 320)    1280        concatenate_195[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 4, 4, 320)    0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 4, 4, 20)     57600       activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_205 (Dropout)           (None, 4, 4, 20)     0           conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_196 (Concatenate)   (None, 4, 4, 340)    0           concatenate_195[0][0]            \n",
            "                                                                 dropout_205[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 4, 4, 340)    1360        concatenate_196[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 4, 4, 340)    0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 4, 4, 20)     61200       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_206 (Dropout)           (None, 4, 4, 20)     0           conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_197 (Concatenate)   (None, 4, 4, 360)    0           concatenate_196[0][0]            \n",
            "                                                                 dropout_206[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 4, 4, 360)    1440        concatenate_197[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 4, 4, 360)    0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 4, 4, 20)     64800       activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_207 (Dropout)           (None, 4, 4, 20)     0           conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_198 (Concatenate)   (None, 4, 4, 380)    0           concatenate_197[0][0]            \n",
            "                                                                 dropout_207[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 4, 4, 380)    1520        concatenate_198[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 4, 4, 380)    0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 4, 4, 20)     68400       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_208 (Dropout)           (None, 4, 4, 20)     0           conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_199 (Concatenate)   (None, 4, 4, 400)    0           concatenate_198[0][0]            \n",
            "                                                                 dropout_208[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 4, 4, 400)    1600        concatenate_199[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 4, 4, 400)    0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 4, 4, 20)     72000       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_209 (Dropout)           (None, 4, 4, 20)     0           conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_200 (Concatenate)   (None, 4, 4, 420)    0           concatenate_199[0][0]            \n",
            "                                                                 dropout_209[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 4, 4, 420)    1680        concatenate_200[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 4, 4, 420)    0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 2, 2, 420)    0           activation_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 1680)         0           average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           16810       flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,159,125\n",
            "Trainable params: 3,121,955\n",
            "Non-trainable params: 37,170\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Zc0wFwgYrmn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath= \"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "#filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2733
        },
        "outputId": "374e5d61-4901-4114-81ea-8243d2c15468"
      },
      "cell_type": "code",
      "source": [
        "'''model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "'''\n",
        "model.fit_generator(train_gen,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    steps_per_epoch=(len(x_train) // batch_size),\n",
        "                    validation_data=test_gen,\n",
        "                   callbacks=callbacks_list)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "781/781 [==============================] - 964s 1s/step - loss: 1.5869 - acc: 0.4204 - val_loss: 1.9470 - val_acc: 0.3943\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.39430, saving model to weights.best.hdf5\n",
            "Epoch 2/50\n",
            " 87/781 [==>...........................] - ETA: 13:02 - loss: 1.2742 - acc: 0.5388"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 936s 1s/step - loss: 1.1528 - acc: 0.5869 - val_loss: 1.9442 - val_acc: 0.4993\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.39430 to 0.49930, saving model to weights.best.hdf5\n",
            "Epoch 3/50\n",
            "141/781 [====>.........................] - ETA: 12:01 - loss: 0.9674 - acc: 0.6510"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 937s 1s/step - loss: 0.9306 - acc: 0.6682 - val_loss: 1.3477 - val_acc: 0.6059\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.49930 to 0.60590, saving model to weights.best.hdf5\n",
            "Epoch 4/50\n",
            "155/781 [====>.........................] - ETA: 11:46 - loss: 0.8381 - acc: 0.7070"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 939s 1s/step - loss: 0.8129 - acc: 0.7138 - val_loss: 1.0934 - val_acc: 0.6672\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.60590 to 0.66720, saving model to weights.best.hdf5\n",
            "Epoch 5/50\n",
            "159/781 [=====>........................] - ETA: 11:39 - loss: 0.7452 - acc: 0.7404"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 938s 1s/step - loss: 0.7267 - acc: 0.7468 - val_loss: 1.1462 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.66720\n",
            "Epoch 6/50\n",
            "185/781 [======>.......................] - ETA: 11:11 - loss: 0.6847 - acc: 0.7618"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 935s 1s/step - loss: 0.6621 - acc: 0.7692 - val_loss: 1.2446 - val_acc: 0.6567\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.66720\n",
            "Epoch 7/50\n",
            "193/781 [======>.......................] - ETA: 11:04 - loss: 0.6353 - acc: 0.7777"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 937s 1s/step - loss: 0.6171 - acc: 0.7856 - val_loss: 1.2189 - val_acc: 0.6815\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.66720 to 0.68150, saving model to weights.best.hdf5\n",
            "Epoch 8/50\n",
            "169/781 [=====>........................] - ETA: 11:29 - loss: 0.5785 - acc: 0.8023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 937s 1s/step - loss: 0.5733 - acc: 0.8007 - val_loss: 0.9353 - val_acc: 0.7309\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.68150 to 0.73090, saving model to weights.best.hdf5\n",
            "Epoch 9/50\n",
            "163/781 [=====>........................] - ETA: 11:37 - loss: 0.5380 - acc: 0.8146"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 937s 1s/step - loss: 0.5425 - acc: 0.8127 - val_loss: 1.0476 - val_acc: 0.7096\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.73090\n",
            "Epoch 10/50\n",
            "185/781 [======>.......................] - ETA: 11:11 - loss: 0.5282 - acc: 0.8153"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 936s 1s/step - loss: 0.5116 - acc: 0.8221 - val_loss: 0.8792 - val_acc: 0.7520\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.73090 to 0.75200, saving model to weights.best.hdf5\n",
            "Epoch 11/50\n",
            "167/781 [=====>........................] - ETA: 11:30 - loss: 0.4987 - acc: 0.8277"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 938s 1s/step - loss: 0.4846 - acc: 0.8326 - val_loss: 0.7484 - val_acc: 0.7706\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.75200 to 0.77060, saving model to weights.best.hdf5\n",
            "Epoch 12/50\n",
            "162/781 [=====>........................] - ETA: 11:37 - loss: 0.4497 - acc: 0.8433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 938s 1s/step - loss: 0.4613 - acc: 0.8398 - val_loss: 0.7419 - val_acc: 0.7762\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.77060 to 0.77620, saving model to weights.best.hdf5\n",
            "Epoch 13/50\n",
            "161/781 [=====>........................] - ETA: 11:40 - loss: 0.4505 - acc: 0.8462"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 937s 1s/step - loss: 0.4419 - acc: 0.8471 - val_loss: 1.0171 - val_acc: 0.7202\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.77620\n",
            "Epoch 14/50\n",
            "185/781 [======>.......................] - ETA: 11:11 - loss: 0.4228 - acc: 0.8531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 935s 1s/step - loss: 0.4217 - acc: 0.8543 - val_loss: 0.5370 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.77620 to 0.83350, saving model to weights.best.hdf5\n",
            "Epoch 15/50\n",
            "167/781 [=====>........................] - ETA: 11:31 - loss: 0.3981 - acc: 0.8657"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 935s 1s/step - loss: 0.4088 - acc: 0.8582 - val_loss: 0.9027 - val_acc: 0.7460\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.83350\n",
            "Epoch 16/50\n",
            "187/781 [======>.......................] - ETA: 11:08 - loss: 0.3786 - acc: 0.8695"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 937s 1s/step - loss: 0.3881 - acc: 0.8651 - val_loss: 0.6594 - val_acc: 0.7984\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.83350\n",
            "Epoch 17/50\n",
            "193/781 [======>.......................] - ETA: 10:59 - loss: 0.3778 - acc: 0.8694"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 937s 1s/step - loss: 0.3790 - acc: 0.8699 - val_loss: 0.6814 - val_acc: 0.7958\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.83350\n",
            "Epoch 18/50\n",
            "195/781 [======>.......................] - ETA: 11:03 - loss: 0.3503 - acc: 0.8801"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 942s 1s/step - loss: 0.3598 - acc: 0.8745 - val_loss: 1.0159 - val_acc: 0.7551\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.83350\n",
            "Epoch 19/50\n",
            "195/781 [======>.......................] - ETA: 11:03 - loss: 0.3439 - acc: 0.8789"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 941s 1s/step - loss: 0.3492 - acc: 0.8777 - val_loss: 0.6776 - val_acc: 0.7962\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.83350\n",
            "Epoch 20/50\n",
            "195/781 [======>.......................] - ETA: 11:00 - loss: 0.3283 - acc: 0.8841"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "654/781 [========================>.....] - ETA: 2:23 - loss: 0.3370 - acc: 0.8830"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1626e7f64478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                    callbacks=callbacks_list)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "37wlxXPr7sgI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2229b0f8-9924-4f72-cc86-f9ef212002e7"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 22s 2ms/step\n",
            "Test loss: 0.6434394887268543\n",
            "Test accuracy: 0.8557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e032cb11-fb86-497c-c0ba-a2c7c99c1e64"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}